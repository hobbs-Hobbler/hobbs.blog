{
    "version": "https://jsonfeed.org/version/1",
    "title": "Cogitate and Percolate",
    "description": "",
    "home_page_url": "https://hobbs-hobbler.github.io/hobbs.blog",
    "feed_url": "https://hobbs-hobbler.github.io/hobbs.blog/feed.json",
    "user_comment": "",
    "icon": "https://hobbs-hobbler.github.io/hobbs.blog/media/website/HD-Logo-Mountain-Sept-2022.png",
    "author": {
        "name": "Heather Dodds"
    },
    "items": [
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/my-privacy-policy.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/my-privacy-policy.html",
            "title": "My Privacy Policy",
            "summary": "With the results of the United States Presidential Election in November 2024, there was a tectonic shift in the thinking of individuals that do want to speak truth to power, but also do not want to be unwise in the act. My blog is primarily&hellip;",
            "content_html": "<p>With the results of the United States Presidential Election in November 2024, there was a tectonic shift in the thinking of individuals that do want to speak truth to power, but also do not want to be unwise in the act. My blog is primarily about speaking the truth about XR for learning around and despite some very powerful companies and a few personal enemies.<br><br>I'm old enough that the lessons of World War II are not lost on me.¬† The time period between November 2024 and this blog going live in June/July 2025 has caused many to harken of 1920s Germany. Indeed, several new phrases have been circulating in my head.<br><br><a href=\"https://snyder.substack.com/p/twenty-lessons-read-by-john-lithgow\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Do not obey in advance</a> is one.<br><br>But another idea is <strong>to not give up my data</strong>, even if I'm utilizing my free speech rights as a US citizen. The idea that one would not be caught up in being arrested or worst <em>if</em> one is doing nothing wrong...is behind us. The monster eats and it eats anyone it can get.</p>\n<figure class=\"d1fekHMv2WPYZzgPAV7b\"><img  src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fbecunningandfulloftricks.com%2Fwp-content%2Fuploads%2F2014%2F09%2Fbe-cunning-and-full-of-tricks-header.jpg&amp;f=1&amp;nofb=1&amp;ipt=9ae1bc74285160c271a98a773ad982ccdd52c376fea91049e584a8ef12a627f8\" alt=\"Be Cunning and Full of Tricks | Exploring Knowledge Management, Online Communities and Virtual ...\" loading=\"eager\" data-is-external-image=\"true\"></figure>\n<div class=\"quoteDetails\">\n<blockquote>\n<div class=\"quoteText\">‚Äú...Whenever they catch you, they will kill you. But first they must catch you, digger, listener, runner, prince with the swift warning. <strong>Be cunning and full of tricks</strong>...‚Äù <br>‚Äï <span class=\"authorOrTitle\"> Richard Adams, Watership Down</span></div>\n</blockquote>\n</div>\n<p><br>That idea lead me to the lovely <a href=\"https://www.optoutproject.net/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Opt Out Project blog</a>.<br><br>Even though I had no direct reason for jumping ship from blogger/blogspot...how MUCH big tech is scraping personal accounts for data now just friggin scares me.¬† I left Twitter/X because of their new policy so take anything anyone posts as food for their AI.¬† I create and share my creations. I was like...uh, no, you are not free to take my stuff.¬† So I left, deleting everything in my wake.</p>\n<figure class=\"post__image align-center\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/740//star-trek-spock-live-long-and-prosper.gif\" alt=\"Gif of Spock saying Live long and prosper when by his face he means fuck off.\" width=\"498\" height=\"211\"></figure><br><br>Leaving blogger/blogspot is another in the steps I'm taking to get away from big tech.<br><br>So that means that you have arrived here. It took me 4 months to get this blog up and running.¬† To the best of my ability, here is what it does.<br><br>1. <strong>I don't care about number counting reads</strong>. Read counts stoke vanity. I've also never activated replies to my posts. If you want to respond, do so on your own blog, thankyouverymuch. üßê I try very hard to not count nor look at the numbers of anything I create.¬† It's not. about. the. numbers. üö´üî¢<br><br>2. This blog is hosted on Github Pages, which is at this time a Microsoft product. <strong>I encourage you to visit using a VPN</strong> because they are probably tracking IPs, but I do not receive the information. <strong>I do not have ANY analytics</strong> that I have activated on this blog.¬†¬†<br><br>3. I'm using Publii and since I only post blog posts and nothing else (no stores, no forms, no mailing lists...I guess the kids call this static HTML now) <strong>I do not plan on adding ANY plugins</strong>. I'm using a basic theme available from Publii.¬† I'll let you know here and in the cookie banner if that changes in the future.<br><br>4. I'm going to attempt to set up the cookie banner to be meaningless for collecting anything and to strongly encourage you to Reject cookies. Let's hope I figure that out.</p>\n<p>Oh and one more thing, <strong>I do not monetize anything here</strong>. Nothing.¬† By willingly turning my back on all forms of monetization, I'm never working for someone else that will show up as bias in my writing.<br><br>As Opt Out Project writes: <strong>No trackers. No fingerprints. No data collection.</strong><br><br>Let us all live long and prosper.</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/740/sasun-bughdaryan-8admGA18lBs-unsplash.jpg",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "privacy",
                   "policy"
            ],
            "date_published": "2025-07-21T18:23:51-04:00",
            "date_modified": "2025-07-21T18:29:26-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-behind-the-scenes.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-behind-the-scenes.html",
            "title": "Instructional Design in the Metaverse: Behind The Scenes",
            "summary": "We should officially start our BTS story with the fact that this writing is a rejected academic book chapter. üò¢ Yeah. No shame, however, tossed towards the editors. Their decision gets to be their decision. I was unnerved that the editors were entirely China-based. I'm&hellip;",
            "content_html": "<div class=\"separator\" style=\"clear: both; text-align: center;\">¬†</div>\n<p>We should officially start our BTS story with the fact that this writing is a rejected academic book chapter.</p>\n<p>üò¢</p>\n<h2 style=\"text-align: left;\">Rejected Book Chapter</h2>\n<p>Yeah. No shame, however, tossed towards the editors.¬† Their decision gets to be their decision.</p>\n<p>I was unnerved that the editors were entirely China-based. I'm not saying one way or the other on that. Just that I'm aware that when political winds change, something that seemed like an OK idea at one point could become a very bad idea later.</p>\n<p>It was a bit of a strange call for chapters in the first place, putting ALL of the approval at the END of the writing process. I went through a review and a rewrite only to be informed after 8 months that my writing didn't seem to fit what the editors were looking for.</p>\n<p>The only tip I'll give about WHICH book it was was that I wrote a long section on myths and that aligned with the book's title.¬†</p>\n<p>But...in the spirit of how the President of Stanford was brought down by what was originally a blog...I figured I'd go for it with self-publishing. Charging for a book? Right now, definitely not my style. Plus, I didn't want to wait another 8 months for another academic publication process. I told some of my ID friends that I would \"juice it up\" for LinkedIn and I did! The original chapter had NO images (strict publisher) and I whooped it up on LinkedIn with all kinds of visual \"borrows\" to help laymen deal with the academic language.</p>\n<h2 style=\"text-align: left;\">Key Points</h2>\n<ol style=\"text-align: left;\">\n<li style=\"text-align: left;\">Continuing to bang my drum on the 3 characteristics that make XR builds successful: <strong>reducing time, money, and/or danger.</strong></li>\n<li>A <strong>focus on plot </strong>as the driving theme of an educational XR experience.</li>\n<li>A focus on <strong>purpose</strong> at every step in the process.</li>\n</ol>\n<p>And these 3 items are not new for me to say. I've been trying to get them into the academy since 2013 with my dissertation, or maybe a little earlier in a few mucky conference papers.</p>\n<h2 style=\"text-align: left;\">Misinformation</h2>\n<p>In my opinion, I pissed off some of both the XR research and XR industry stakeholders. And I got two rebuttals. The most attention and chuckling came from me doing a TLDR on the <a target=\"_blank\" rel=\"noopener noreferrer\">myth section</a> and just coming out and saying</p>\n<blockquote>Virtual Reality Causes Faster Learning - Myth</blockquote>\n<p>That was surprising-- mostly because I don't expect to turn any aircraft carriers with that language. Did I? Time will tell.</p>\n<p>Indeed, support for and any engagement with the articles dropped off over time. It was as though literally if one posted ANYTHING with the word Metaverse it in, a whole crowd of whoopdeedooers üéâüòÄü§òüéâ would drop by, hit the clap button üëè, wish you well and...disappear.¬† I mean I felt I wrote some uplifting, helpful, and cheap (for the price) advice in the latter articles and there were...crickets.</p>\n<h2 style=\"text-align: left;\">Coda</h2>\n<p>There is too much XR-for-education misinformation going on out there for me to remain quiet on some of this shit.</p>\n<p>Just this morning, I woke up to find fresh serving in my LinkedIn feed.¬† It's like I want to take a break from writing but the crap keeps flowing in the door.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/crap-Instructional-Design-in-the-Metaverse-BTS.png\" alt=\"Screen capture of &quot;report&quot; text: The numbers show that virtual reality in the workplace can improve communication, togetherness, output satisfaction, and the experience of working together in virtual workshops.\" width=\"772\" height=\"117\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/responsive/crap-Instructional-Design-in-the-Metaverse-BTS-2xl.png 1920w\"></figure>\n<p>In one sentence, nearly every good research rule was broken:</p>\n<blockquote>The numbers show that virtual reality in the workplace can improve communication, togetherness, output satisfaction, and the experience of working together in virtual workshops.</blockquote>\n<p>\"The numbers show\" - that's an appeal to research results.¬† What they mean is THEIR numbers from THEIR study which was not really structured as research at all. It was structured as a rah-rah-sis-boom-bah don't-we-love-the-newest-shiniest-thing data collection exercise.</p>\n<p>\"Improve communication\" - how? how measured?</p>\n<p>Improve [implied] togetherness - how measured?<br><br>Improve [implied] output satisfaction - that is a \"like\" study, which means nothing to productivity. Tricky there....using \"output\" to make you think these might be widgets. Nope.</p>\n<p>Improve [implied] the experience of working together in virtual workshops.¬† You know what ALSO improves the experience of working together in virtual workshops? Free food.</p>\n<p>All that implication was a bit of a grammatical somersault but alas, it is what it is.¬†</p>\n<p>Hopefully if you understood my point, you'd see that these \"numbers\" refer to novelty effect.¬† Pretty much on the nail head.¬† People had fun because it was new. It won't always be new, so be careful.¬†</p>\n<h2 style=\"text-align: left;\">AI</h2>\n<p>Because I wrote and published this article series in 2023, a valid question must be asked:¬†</p>\n<p>Did I use AI at all in the writing of this?<br>Answer: <strong>Yes. And I'll tell you exactly where.</strong></p>\n<p>When I was proofreading myself (so long after finishing writing), I wanted to check on a somewhat novel phrase that I was using (coining?) just to make sure that my intended meaning matched what others might think it means.</p>\n<p>I asked Bing to clarify the difference between these 2 phrases:</p>\n<ul style=\"text-align: left;\">\n<li>Non-cognitively comparable methods</li>\n<li>Non-comparable cognitive methods</li>\n</ul>\n<p style=\"text-align: left;\">Sure enough, Bing helped clarify that the 'non-' in front is the item negated. That is:<br>Non-cognitively comparable means that something <strong><i>is</i></strong> comparable but the DIFFERENCE is in the cognition. That's exactly what I meant; <strong><i>the brain burden is different.¬†</i> </strong>This occurs when studies try to compare textbook learning to VR learning. It's non-cognitively comparable. Therefore, null results.<strong><i> </i></strong>It's like dividing by zero.<strong><i><br></i></strong></p>\n<p>Non-comparable cognitive methods assumes that both methods are cognitive (yeah, duh) but that they are not comparable. No, that's NOT what I meant. People try comparing like crazy, even if I don't like it.</p>\n<p>So I stuck with my original writing and phrase: non-cognitively comparable.</p>\n<p>And that's the only AI I knowingly used. It's possible that Google Scholar had some AI with reference writing?? But I don't know that. That's sort of pre-AI because really a reference is just an act of putting the right thing in the right place with the right formatting. It can be driven by code...not by some sort of intelligence.</p>\n<p>I did use Midjourney to make the artwork but that was completely separate from the writing (and was really fun and educational!)</p>\n<h2 style=\"text-align: left;\">Conclusion</h2>\n<p>In summary, in over 12,000 words, is there anything more I can say that I didn't cover?</p>\n<p>Yes.</p>\n<p>I sincerely hope that my freely given advice is not lost on decision makers. I constantly write <i>for</i> someone with her hands on a multi-thousands or multi-millions of dollars budget and she needs to KNOW WHAT TO DECIDE when she gets an XR or virtual reality for education proposal on her desk.</p>\n<p>I wrote all of this with NO tie to money whatsoever. I'm not employed. I do not work for a company that will sell you XR.¬† I'm not working as an instructional designer pushing XR choices on my bosses.¬† LinkedIn articles, unlike Medium articles, provide NO pay-per-click (although, to be fair Medium pays less than pennies per click..so comparing pennies to nothing is a bit of a low blow). I do not have a monetized YouTube account. I don't have anything social media wise that makes me money.¬† I'm \"employed\" at my own Consulting business but that is just a front to make me \"look\" employed to LinkedIn. I've done no work for pay in 2023. Actually, during the writing and publication, I don't own a car so I used the public bus and I utilized the provisions of a food pantry.¬†¬†</p>\n<p>I have nothing at stake to sway a person one way or another. I'm simply calling out where the research points. I do hope it will be of value to someone.</p>\n<p>Here's my LinkedIn video summary of the 8 articles. In under 3 minutes, you can get it all! The bad news? It will come at you VERY fast.¬†</p>\n<figure class=\"post__video\"><iframe loading=\"lazy\" width=\"560\" height=\"314\" src=\"https://www.youtube-nocookie.com/embed/Rr4dzKLPlpQ\" allowfullscreen=\"allowfullscreen\" data-mce-fragment=\"1\"></iframe></figure>\n<hr>\n<p>This blog post was originally published on November 7, 2023.</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/732/heather_dodds_in_Blade_Runner_style_science_fictiondark_moonbas_b553ee9d-56e7-4f55-865a-f5e3fd334736-2.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-11-07T16:41:00-05:00",
            "date_modified": "2025-08-02T15:52:43-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-8.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-8.html",
            "title": "Instructional Design in the Metaverse Part 8",
            "summary": "We've arrived at Part 8 of this series which proposes instructional design principles for the metaverse. It's the season finale! First, no researcher worth their salt would give so much advice without acknowledging where the whole thing falls apart-- known as the \"Limitations\" section of&hellip;",
            "content_html": "<div>¬†</div>\n<p>We've arrived at Part 8 of this series which proposes instructional design principles for the metaverse. It's the season finale!</p>\n<p class=\"article-editor-content__paragraph\">First, no researcher worth their salt would give so much advice without acknowledging where the whole thing falls apart-- known as the \"Limitations\" section of writing.</p>\n<p class=\"article-editor-content__paragraph\">Second, my absolutely favorite, top, best, most loved tip of all is here. Thesaurus dot com tells me that another word for it \"happenstance\"-- which is a word I do use. Alas, serendipity sounds more eloquent.</p>\n<p class=\"article-editor-content__paragraph\">Finally, the conclusion. We're at the bottom of the ski jump; it's moments before I launch you out. What have you learned? Have you learned how to read research? Have you learned what makes a design strong? Have you learned that the <i>media of the metaverse</i> is minor but it is the emotion that makes it work?</p>\n<p class=\"article-editor-content__paragraph\">Reach out with your feelings, Luke.</p>\n<h2 class=\"article-editor-content__heading\">Limitations</h2>\n<p class=\"article-editor-content__paragraph\">What are the weaknesses in applying what we already know about 2D ID to 3D environments? Learner-centric design uses the dual channel coding theory as a basis. That theory restricts information input to the two sense channels: sight and sound. This served instructional design well when education was face-to-face or e-learning. XR, however, can add other senses, haptics, smell, and taste. The input of learning information via other senses is largely unexplored territory.</p>\n<figure class=\"post__image\" ><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/Mayer-modified.png\" alt=\"Edited capture of Mayer's Dual Channel hypothesis diagram with added text: What about our smell, taste, touch, and body position senses? How will XR use these senses for learning? The research does not say...yet.\" width=\"2240\" height=\"1260\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Mayer-modified-2xl.png 1920w\">\n<figcaption >If we should reduce cognitive workload from text and sound conflicts, how will smell, taste, touch, and proprioception intersect with learning?</figcaption>\n</figure>\n<p class=\"article-editor-content__paragraph\">For example, haptic and temperature feedback are currently added to XR firefighter training. The limitation in the hypothesis of this article series could be that it fails to acknowledge what role these other senses will play in the future. In short, it is possible that the dual channel coding assumption might need to be expanded in the future to engage more channels.</p>\n<p class=\"article-editor-content__paragraph\">Further, it is very difficult to predict an entire design plan from just one viewpoint. For example, using narrative plot sounds like an excellent approach, but it would fall flat during direct instructional approaches because the learner does not drive that approach.</p>\n<p class=\"article-editor-content__paragraph\">This series advocated for purpose and emotion within 3D design but those approaches are not meant to be used only at the planning and designing stages. There should be an ebb and flow between the instructional designer (ID) and all stakeholders, testing and re-asking what the XR space is designed to do. <strong>Applications beyond what have been already researched or envisioned will surely test this article series' reasoning in new dimensions.</strong></p>\n<p class=\"article-editor-content__paragraph\">Finally, it should also be acknowledged that an article series on the use of the XR in ID does not intend to malign or downgrade other media for learning. Instead, the purpose of this series is to provide early guidance in a developing area. Slowly the research field gathers information that the next generation of IDs can use.</p>\n<h2 class=\"article-editor-content__heading\">Serendipity</h2>\n<p class=\"article-editor-content__paragraph\">Sometimes, something magical happens that even the instructional designer (ID) did not imagine. These moments can be the most endearing and creative for learners. These serendipitous moments often happen far beyond the bounds of the design and programming. For example, in Poland, teachers who had never used VR before received 30 minutes of training before entering the game Half-Life: Alyx to teach language, math, and science (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.uploadvr.com/teachers-poland-half-life-alyx-vr/\" rel=\"noopener noreferrer\">Bretan</a>, 2020).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN.png\" alt=\"Capture of teaching math from inside Half-Life: Alyx\" width=\"1901\" height=\"1034\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/Screenshot-2023-10-20-at-12-17-11-Teacher-Uses-Half-Life-Alyx-To-Deliver-Math-Lesson-In-VR-IGN-2xl.png 1920w\"><figcaption>Source: Teacher Uses Half-Life: Alyx To Deliver Math Lesson In VR</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Learners discover how to fall through ramps and piggy-back on other avatars when playing with surface and wall programming. Spontaneous games break out like follow-the-leader. Learners have walked into the middle of roaring virtual campfires - just to see what it was like. An XR volcano scene spontaneously created a Star Wars story.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/The-Chosen-One.png\" alt=\"Capture of volcano build where users spontaneously acted out a Star Wars scene between Obi-Wan Kenobi and Anakin Skywalker.\" width=\"2240\" height=\"1260\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/The-Chosen-One-2xl.png 1920w\"><figcaption>Warning: Getting into lava can lead to the dark side.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\"><strong>Human behavior in practical applications escapes around theories like water around a dam.</strong></p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">This makes educational research different from controlled laboratory studies; while we hope for what is predicted, <strong><i>humans can delightfully exceed their programming. </i></strong></p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">The combination of curiosity, exploration, and bravery cannot always be planned for in a learning design. It should not be squashed.</p>\n<p class=\"article-editor-content__paragraph\">Therefore, <strong>leave space in designs for the unexpected;</strong> do not plan every moment.</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">Leave space for serendipity.</p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">This can look like leaving time for learners to get used to their avatars, let them practice grabbing and tossing 3D objects, and let them use spaces in unexpected ways. Have warm-up type of events before more formal learning events. Let learners explore freely through a space before calling them back for a learning event.</p>\n<p class=\"article-editor-content__paragraph\">In <strong><i>these</i></strong> moments, <strong>learners</strong> can show <strong>IDs</strong> what XR can <i>really</i> do.</p>\n<h2 class=\"article-editor-content__heading\">Conclusion</h2>\n<p class=\"article-editor-content__paragraph\">To conclude, this series covered the frequently cited research myths surrounding the use of XR in education. It also brought to the forefront the three characteristics to look for when evaluating possible XR solutions: Does it reduce time, money, or danger? It went through the principles of multimedia design to show how they would apply to 3D designs‚Äìseparating out what affordances would behave the same (paying close attention to cognitive processing) and what affordances would be different (realizing that 3D basically means more everything- more visuals, more sound, more motion, and emotion- around a learner). It contained some design advice that needs to be remembered when dealing with the metaverse; focus on purpose, design for emotion, and remember real world correlations.</p>\n<p class=\"article-editor-content__paragraph\">From this, it might be valid to infer that this article series portrayed research myths at the periphery of publishing while creating a pessimistic view of the possibilities of XR - the proverbial cold bucket of water thrown on the excitement for the metaverse. Indeed, <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://edtechbooks.org/foundations_of_learn/also_32_media_method/simple\" rel=\"noopener noreferrer\">Honebein and Reigeluth</a> did not mince words when they advised that IDs:</p>\n<p class=\"article-editor-content__paragraph\">\"<strong>Be cautious </strong>of experimental, research-to-prove comparison studies that include media or combine media and instructional methods. In other words, buyer beware. This research is not useful because it might:</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Suggest that learning effectiveness is improved by the media, when in fact it is improved by the instructional method.</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Influence practitioners to choose media that likely won‚Äôt work for their situation.</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Represent quick and dirty publications that are intentionally or unintendedly meant to pad a researcher‚Äôs portfolio for promotion, salary increase, and tenure. <strong>In other words, the paper benefits the author, not the reader.</strong></p>\n</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">When designing a learning experience, follow the processes associated with the theoretical framework\" (2023, p. 13, added emphasis mine).</p>\n<p class=\"article-editor-content__paragraph\">IDs will need to stand up and state that some uses of the metaverse are not recommended. IDs will be required to closely examine research. The best uses of XR technologies will be when XR reduces or manipulates time, saves money, or reduces danger. Technologies such as simulations or branding scenarios already compete closely on those three characteristics. Designs should be approached in a learner-centric manner, using design techniques such as narrative plot or the XR strengths in visuals, sound, and interaction. Designs should lean towards the conservative.</p>\n<p class=\"article-editor-content__paragraph\">This vista ahead, however, is bright. There is enticing area that we‚Äôve not yet traveled into fully: the fully nuanced role of emotion in learning as that intersects with the metaverse. Mayer ended his tome on multimedia learning in 2020 acknowledging that while seductive details are irrelevant to learning, designing <strong><i>emotion</i></strong> <strong>purposely into learning</strong> seems to intersect with self-efficacy‚Äì a factor known to create motivation for learning. To be clear, this means designing in non-player characters (NPCs) or scenarios where emotion is purposely present.</p>\n<p class=\"article-editor-content__paragraph\">Mayer is not the only major researcher starting to look towards emotion. Honebein and Reigeluth posited that appeal is part of the Instructional Design Iron Triangle, with effectiveness and efficiency. Appeal makes learning recommendable or to use another phrase, creates repeat customers (2023, p. 7). This author herself hears directly from many educators that observe that learners are drawn to this medium in ways not seen before, with the common trait being <i>the social aspect</i> of being able<strong> to feel</strong> <i>together</i>: a shared feeling and communication. The users that exit XR the fastest seem to be those that never interact with another person in an XR space. What's happening there will have to wait for the next Pasteur‚Äôs Quadrant article.¬†</p>\n<p class=\"article-editor-content__paragraph\">The possible uses of the metaverse in education are diverse, creative, and beautiful that to commodify it would be to harm it. Instructional designers should open their imaginations to see new vistas, thinking of the Metaverse‚Äôs <i>best</i> uses, equipped with what we already know to meet the new challenges in learning.</p>\n<p class=\"article-editor-content__paragraph\">May the Blessing of the Metaverse be with you.</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsVKbGEEZwtAZ3IKiDT60me-0F8X3frB8DO6L2kKy1C6Uk0VP3Vt82SfnoP8XSAylHj8qW1S2qp3rJw6GB9AFFP9nxrPt4O0t-vJxwEH5fDArSsox_Om0T0Y8jLGfucfn2_7v_HA9aOi9vwW4zxDAMJ-1UTOIMEbxqPCnRPQ9rkq82LaNhCgfrnGXivAY/s2184/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea.png\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea.png\" alt=\"Wider decorative image of Our metaverse explorer as she heads off into the golden sun.\" width=\"640\" height=\"240\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/responsive/heather_dodds_Close_shot_side_shot_an_adventurer_wearing_a_hood_7184633d-8851-4869-922f-d24dacb07aea-2xl.png 1920w\"><figcaption>Prompt:¬†<span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">Close shot</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, side shot</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, an adventurer wearing a hooded cloak</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, climbs a mountain into golden clouds</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, </span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, in the style of deep indigo</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, light silver</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, enchanting lighting</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, fantasycore</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, blue and green color scheme</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">, no face </span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">-</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">-ar </span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">1</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">6</span><span style=\"--tw-border-spacing-x: 0; --tw-border-spacing-y: 0; --tw-ring-color: rgb(59 130 246 / 0.5); --tw-ring-offset-color: #fff; --tw-ring-offset-shadow: 0 0 #0000; --tw-ring-offset-width: 0px; --tw-ring-shadow: 0 0 #0000; --tw-rotate: 0; --tw-scale-x: 1; --tw-scale-y: 1; --tw-scroll-snap-strictness: proximity; --tw-shadow-colored: 0 0 #0000; --tw-shadow: 0 0 #0000; --tw-skew-x: 0; --tw-skew-y: 0; --tw-translate-x: 0; --tw-translate-y: 0; border: 0px; font-family: inherit; font-size: 16px; font-style: inherit; font-weight: inherit; margin: 0px; padding: 0px; vertical-align: baseline;\">:9</span></figcaption></figure>\n</a></div>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p>[Edit: these links will route back to my old blog location until I update them.]</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-1.html\" rel=\"noopener noreferrer\">Part 1</a> was the Introduction.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-2.html\" rel=\"noopener noreferrer\">Part 2</a> covered Theory and Scope.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part.html\" rel=\"noopener noreferrer\">Part 3</a> was Myths versus Reality.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_8.html\" rel=\"noopener noreferrer\">Part 4</a> covered the Characteristics of Success.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_10.html\" rel=\"noopener noreferrer\">Part 5</a> was What is the same between 2D and 3D design?</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_02074647801.html\" rel=\"noopener noreferrer\">Part 6</a> was What is different between 2D and 3D design?</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_0947144057.html\" rel=\"noopener noreferrer\">Part 7</a> was Design and Build.</p>\n<p class=\"article-editor-content__paragraph\">Want to see my full references? <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse.html\" rel=\"noopener noreferrer\">Have at it</a>.</p>\n<p class=\"article-editor-content__paragraph\">Bonus content!¬† My behind the scenes post on this article series is <a href=\"https://heatheredodds.blogspot.com/2023/11/instructional-design-in-metaverse.html\">here.</a></p>\n<hr>\n<p class=\"article-editor-content__paragraph\">#InstructionalDesign #XR #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #edtech #Approach #LearnerCentric #Limitations #SmellOVision #TasteOVision #Touch #Haptic #Proprioception #Serendipity #Happenstance #Chance #Random #Human #Surprise #Wonderful #ExceedsProgramming #TheRoleOfEmotion #Emotion #Motivation</p>\n<p class=\"article-editor-content__paragraph\">This was originally posted on October 22, 2023.</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/733/ID-in-the-Meta-Part-4.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "XR",
                   "Wonderful",
                   "Touch",
                   "The Role of Emotion",
                   "TasteOVision",
                   "Surprise",
                   "SmellOVision",
                   "Random",
                   "Proprioception",
                   "Motivation",
                   "Metaverse",
                   "LXD",
                   "Human",
                   "Haptic",
                   "Happenstance",
                   "Exceeds Programming",
                   "Chance"
            ],
            "date_published": "2023-10-22T15:13:00-04:00",
            "date_modified": "2025-08-02T15:39:56-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-7-design-and-build.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-7-design-and-build.html",
            "title": "Instructional Design in the Metaverse Part 7 Design and Build",
            "summary": "At this point, we have all of the building blocks ready to begin a design. We know what works from 2D learning and what to try with 3D learning. Beginning the steps to launch an XR experience can feel more like a User Experience (UX)&hellip;",
            "content_html": "<p>¬†</p>\n<p class=\"article-editor-content__paragraph\">At this point, we have all of the building blocks ready to begin a design. We know what works from 2D learning and what to try with 3D learning. Beginning the steps to launch an XR experience can feel more like a User Experience (UX) project than an instructional design project, however. UX similarly uses storyboards, journey mapping, and personas which can be very helpful in designing emotion into the experience. Prototype versions can be ready for a few users to sample and give feedback. Overall, ID projects in the metaverse feel different because the designing and building phases <i>blend together</i> with test layouts requiring adjustment.</p>\n<p class=\"article-editor-content__paragraph\">Even at the final project launch, instructional designers (IDs) should observe how the learners are experiencing the design. IDs should be at the forefront with the learners, constantly evaluating what is working and what is not. It can be very helpful for IDs to observe what learners try first or how they explore the experience. In this way, design with this media is less of a one-way instance and more of an ongoing process. Remember <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=PXRJEAAAQBAJ&amp;lpg=PP1&amp;ots=UpbIsA4SJU&amp;dq=learning%20experience%20design%20Clark&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">D. Clark's</a> 'always beginning, never ending' design advice? The following three sections represent lessons already learned in ID for XR designs.</p>\n<h3 class=\"article-editor-content__heading\">1 Focus on Purpose</h3>\n<p class=\"article-editor-content__paragraph\">Determining purpose at the earliest stage is critical because the purpose guides many of the upcoming ID decisions. Traditional ID projects begin with these questions that ask about the main learning objective or goal.</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">\"What will students be able to do at <strong>the end of the course</strong>\" (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://teachingcommons.stanford.edu/teaching-guides/foundations-course-design/theory-practice/teacher-centered-vs-student-centered\" rel=\"noopener noreferrer\">Stanford University</a>, 2023).</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">‚ÄúFocus on <strong>performance requirements</strong>‚Äù (Guy Wallace as quoted in <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://endurancelearning.com/blog/id-for-non-training-professionals/\" rel=\"noopener noreferrer\">Washburn</a>, 2023).</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">‚ÄúIdentify desired <strong>results</strong>‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://tll.mit.edu/teaching-resources/course-design/backward-design/\" rel=\"noopener noreferrer\">MIT Teaching and Learning Lab</a>, 2023).</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">‚ÄúThink about what <strong>people are truly trying to do</strong> and realize that‚Äôs a system‚Äù (Don Norman as quoted in <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://blog.adobe.com/en/publish/2017/10/03/putting-people-first-tips-and-advice-from-ux-pioneer-don-norman\" rel=\"noopener noreferrer\">Faller</a>, 2017).</p>\n</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">However, because the metaverse is an experience for the learners, it can be thought of as a place and time; it is like a field trip.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhQdOoLUZQKa0Uh3shnPex7HElKkgD3agXf2yLpSc_-hB3cqx4nMhQbtJVzLQ9LmICQabtGUHXdCWYetPv5X_KT5z8J03J1qQwE4h23MCuw4xz7_YVN0e_xcXBNg2ZNk1hRSDZRrU31QA2VB2U5Elp9IpFya9tNnSdOEmCgzqg85wNq2O0Ic7CLkrL_wMg/w640-h428/Sistine%20Chapel%20(actual).jpg\" alt=\"Photo interior of the Sistine Chapel with painted walls and ceiling.\" width=\"640\" height=\"428\" border=\"0\" data-original-height=\"1555\" data-original-width=\"2323\" data-is-external-image=\"true\"><figcaption>Sistine Chapel (actual)</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Here is an example: An art history instructor wants to recreate a visit to the Sistine Chapel. Rather than first creating an XR building or finding an XR recreated chapel, the ID can determine what is the most important experience for the learner. It could be:</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Appreciating Michelangelo‚Äôs artistic style</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Imagining how the artist would have painted in the space</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Discussing the role of sponsors for art</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Viewing the artwork like real life (looking up)</p>\n</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">Each of those different purposes could generate a different learning design.</p>\n<p class=\"article-editor-content__paragraph\">Let‚Äôs say the instructor wants to emphasize<strong> viewing the artwork within the chapel, on the curved ceiling and the soaring upper walls and how this viewing angle intersects with perspective</strong>. Noting prior experiences, learners might have only seen this art <i>somewhat</i> straight-on from photographs.¬†</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg-K1xbwtU9xkxvlHuKtVfGHeQTU8UedVJ0rAA0KSaNbsCfcXcGPBApL8vAFXV1cCYWKIi7w4sWcJOo4QmF0vu69bf67UaBsl9uazUlQhwzglbBjIJO5Lx9E50JpYJ90AzyUqpFmB72oTax0SpSstZ5L858kefPtHwfY5E_aZY-RrLHUGcdJ2kUUiSEOAE/s1793/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7.jpg\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7.jpg\" alt=\"Photo of the Noah ceiling bay at the Sistine Chapel. Viewing straight up into a ceiling bay. Note that from this view, both left and right are looking down, even when you are looking up.\" width=\"640\" height=\"178\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-xs.jpg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-sm.jpg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-md.jpg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-lg.jpg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-xl.jpg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Michelangelo_-_Sistine_Chapel_ceiling_-_bay_7-2xl.jpg 1920w\"><figcaption>Viewing straight up into a ceiling bay. Note now from this view, both left and right are looking down, even when you are looking up. Michelangelo?! Escher much?</figcaption></figure>\n</a></div>\n<p class=\"article-editor-content__paragraph\">In real life, the art appears above the viewer. Thus, there are two different points to view from: in photographs, the view is from what would be mid-air. In real life, the view is from the ground.¬†</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgQI-bR3pi023lvvxv0tctbjVDr4pTAkIQkZvt7rxb0vPkPxSkNn-mXR94Zp_2EQSxF_gsjoFB1YsUgIrChiB-cj0JjpMp1wpztf4u1NnGOWy3rKQ-U_yDeS3QLE6xXoWOw3RoCg0XvZwo_gibHXvLHBV71yike7Y3HjTjLL8oQUM3ow2vtkMQ5zZn9tak/s1024/Sistine_Chapel_ceiling_(3395223825)_editted.png\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/Sistine_Chapel_ceiling_(3395223825)_editted.png\" alt=\"The Noah bay in context of the full ceiling where the shadow effect of a left and right curving side now make more visual sense above the chapel walls.\" width=\"486\" height=\"640\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/Sistine_Chapel_ceiling_(3395223825)_editted-2xl.png 1920w\"><figcaption>Same ceiling bay, showing how the side pieces appear to \"curve down\" to vertical walls, creating a left/right sides illusion. So...WHAT is the PURPOSE you want to teach?</figcaption></figure>\n</a></div>\n<p class=\"article-editor-content__paragraph\">In XR, designers could use either or both. The learners might be able to first view the artwork from the floor and then <strong>fly</strong> and compare looking at the art from mid-air. In this way, the learners will have comparative viewing from different angles‚Ä¶something that the real life Chapel can not easily provide. This satisfies the instructor's request to focus on the viewing experience by providing a standard replication and then a different angle as comparison.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjT-SK3eX6qkUOBEd98qNugyWbe2PcbwHTpkXmOg01IzBUR5ZN7czDrDNaeUzU9hxJiOgPDxSRNypt2-0XrE_ysSliZfIwtazZ0BXsG-JUmqT_ly1Bh_OxnIJOaHee-hSsGCw_1qvCskvxRE8EI3W-NmE1mlR_WGAasYE03QEK5DAYFw8NzXT5XwQp8kXc/w640-h360/Title%20Page(1).png\" alt=\"Side by side photo comparison of the real Sistine Chapel and a virtual Sistine Chapel. Except for some light, nearly indistinguishable from each other.\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"1080\" data-original-width=\"1920\" data-is-external-image=\"true\"><figcaption>Side by side photo comparison of the real Sistine Chapel and a virtual Sistine Chapel. Except for some light, nearly indistinguishable from each other.¬†</figcaption></figure>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhPm_KiPFstWWt45wlhJ4JW-8ndGFXrsZSTTBVvew9HzGeZL778w6ws0FgySrKJaqxim53cW9S-aIj6no66FWgzLBtN4aIXtau6gUnE5MYHZmPPORkmS2zwrtq32mNxFYxHePalGDEDx7T2rW6h5naNmnSCz-nXMfFBcD2kMqM17sq_TArrEIsBTrc60Nc/w640-h360/Sistine%20Chapel%20for%20sale.png\" alt=\"A virtual Sistine Chapel is for sale at Sketchfab\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"748\" data-original-width=\"1327\" data-is-external-image=\"true\"><figcaption>Sistine Chapel - virtual is for sale for $39 US at Sketchfab</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">By thinking about the learner‚Äôs experience, the designer can start to list which aspects of the real world need to be replicated (e.g., gravity, enclosed space) and which aspects will not be from reality (e.g. flying on demand). In summary, <strong>this adage fits: begin with the end in mind.</strong></p>\n<p class=\"article-editor-content__paragraph\">For XR designs, ask ‚Äúwhat is the feeling that you want your learner to have?‚Äù That might come as a surprise‚Äì elevating feeling as a primary design priority. The next section will address why the feel of an XR design is more important than its content.</p>\n<h3 class=\"article-editor-content__heading\">2 Emotion Transcends Language</h3>\n<p class=\"article-editor-content__paragraph\">Pixar is a highly successful <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.nyfa.edu/student-resources/pixars-rules-for-great-storytelling/\" rel=\"noopener noreferrer\">storytelling</a> company. In the Pixar narrative model, the highest production emphasis is placed on the emotions within the story (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://youtu.be/1rMnzNZkIX0\" rel=\"noopener noreferrer\">Khan Academy Labs</a>, 2017). Characters and setting are considered secondarily.¬†</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTYzaFGXc9pBOvMegjCPpSgdG9U2ySyenApxFScQzNsCaTT9dyHuuCrc8t6HPdXv8jIITJLusbJpFQd9jAp56WFBvrpwj0xdR2W3zzgutS6i8zj06hVK7AwUT79ul0-2LJBDuNsjwyRVR-h1iKxpid5AHQJ75hekENtRghJPtjD0mEIVZauJWEo4nkDZU/s818/The_Incredibles_-_colorscript-796068816.png\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/The_Incredibles_-_colorscript-796068816.png\" alt=\"Lou Romano created wordless, colored storyboards for The Incredibles based on a 1960s esthetic. It worked\" width=\"640\" height=\"640\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/The_Incredibles_-_colorscript-796068816-2xl.png 1920w\"><figcaption>Lou Romano created <strong>wordless</strong>, colored storyboards for The Incredibles based on a 1960s esthetic. It worked. Everyone else could build from these emotion-evoking images.</figcaption></figure>\n</a></div>\n<blockquote class=\"article-editor-content__blockquote\">\n<blockquote><strong>Emotional coinage works in XR storytelling because emotion transcends language;</strong> it does not need a text pop-up or an AI translator.</blockquote>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">When an emotion can be relayed in some sort of visual or sound media, the designer can worry less about language translation or exactness in the metaverse. XR works naturally in this realm. Combining emotion with narrative plot creates designs where the learner is truly at the center because the learner becomes the lead character in the story. They are pulled along the learning journey because their character (their avatar) is experiencing the story.¬†</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi-PuFhQcjWYOvBUiG62dENiImnIt24D6cR5OvcsgEob2w4avvB5GFJZn1P_y1yl81WqgxhmOuqj12-eS6qWJuQjVyIhnORfTuWv62mWp0ymY7pA9OhWX7TvovorPouaniFKexriZJ1PfVsrAS9lQtLb1_epEQtn08wixg4qDvWpjQ0PtLy4d0g6daA6uw/s474/th-2487672165.jpeg\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/th-2487672165.jpeg\" alt=\"Disney advertising graphic from Secrets of the Empire, Star Wars. A robot gestures to children to help in the fight against Star Troopers.\" width=\"640\" height=\"360\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-xs.jpeg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-sm.jpeg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-md.jpeg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-lg.jpeg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-xl.jpeg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/th-2487672165-2xl.jpeg 1920w\"><figcaption>Credit: Disney. Concept art showing 3 great things: 1 A clear \"invite\" to join the story 2 Headsets and non-headset users portrayed simultaneously. 3 Girls clearly invited, who are, apparently, good shots.</figcaption></figure>\n</a></div>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://youtu.be/4o__z7aPlMw?si=PvpIGHdsJdL-IVs2&amp;t=198\" rel=\"noopener noreferrer\">Alger</a> illustrated these atomic design elements used to relay emotion: line, color, motion, lighting, spatial arrangement, sound timbre, haptic sensations, user proprioception, or visual elements like iridescence and specularity (2020).¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgrv9QGdxfuRvmtDB1KQQXn1VRcqzADt0RbkXfM3vDJCf46UWmHwFApYY6yFs2Th9IcVhpXtDnfxN4_dV9O1vPzdFNMp0qeq8dbzbkcVT3EdvUbQQ9gr_9b1yZg5utfS8_mX8qdWUUJrdPgW7XvTjp7SFdfuS8zUDrbl6gasJ_dFECRCW4ErLsPN_w2dQo/w640-h360/Title%20Page.png\" alt=\"Four panel graphic with text: How design creates feeling with examples from line, color, movement, and form/shape. Credit: Alger 2020.\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"1080\" data-original-width=\"1920\" data-is-external-image=\"true\"><figcaption>Alger, 2020.¬†</figcaption></figure>\n<div class=\"separator\" style=\"clear: both; text-align: center;\">¬†</div>\n<div class=\"article-editor-content__iframe-embed\">Just the basics of <strong>visual</strong> design, there is so much more for XR including sound design, body movement and placement, temperature and pressure, and smell!</div>\n<p class=\"article-editor-content__paragraph\">IDs might want to work with designers from industrial or interior design, architects, or public space planners. [Hot tip: want to read more? The Internet Library has <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://archive.org/details/the-pocket-universal-principles-of-design-150-essential-tools\" rel=\"noopener noreferrer\">The Pocket Universal Principles Of Design 150 Essential Tools</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEilWvgewhZCCDKrVUz6Gx1AKo_akwdESdwPnK1u38hAJy11zOegTVha1ycSxgv8YeAeZaNGrlKZAocNfuiMGK2VXank0f9tvatOkrrCC2ah5r0xrR1lNHoWNI0FV8-9hgeH6f5XhsLGN2ufT-mIahA3UwqDp2LSzxPPiO5UdbfHUp36pdCL4ORUpKvKilc/w640-h444/Principles%20of%20design%20book.png\" alt=\"Capture from inside  The Pocket Universal Principles Of Design 150 Essential Tools with diagram showing that high ceilings evoke creativity and low ceilings foster focus.\" width=\"640\" height=\"444\" border=\"0\" data-original-height=\"993\" data-original-width=\"1430\" data-is-external-image=\"true\"><figcaption>I like this page particularly linking ceiling height with \"feeling\" in spaces, proposing the high ceilings spur creativity whereas low ceilings foster focus.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">In planning a design, IDs can ask the instructor what the main emotion is that they want their learners to feel within the space (curiosity, happiness, fear, proficiency, etc.).</p>\n<p class=\"article-editor-content__paragraph\">The emotions can, of course, change as the story changes. In prototypes, IDs should ask learners what feelings they have in the XR space. Does the feeling match the purpose/goal? If not, the design needs to be changed to foster the emotion that is intended.</p>\n<h3 class=\"article-editor-content__heading\">3 Real World Correlation</h3>\n<p class=\"article-editor-content__paragraph\">After the purpose is established and the central emotions are noted for a learning experience, the ID can determine how much of a real world correlation there is to the XR experience.</p>\n<blockquote>\n<p>For instance, when coming up against a design challenge in XR, IDs should ask, ‚ÄúHow is this done in the real world?‚Äù</p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">The answer might be that the learner does a behavior (e.g. takes notes or alters a piece of equipment) or retrieves more information (e.g. looks at a reference source). With some consideration, the real world solution can be strategized together with the Multimedia Principles and created in XR. For example, if learners are struggling to remember a series of steps, do they need a nearby poster as a visual aid? If learners are getting something wrong with timing, do they need a stopwatch or clock? In XR, posters and clocks do not need to necessarily <i>hang on walls</i>.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi22vDEFrTPHixDsS5V2xQlYId8EbhlZ5hbNTeroaxQCL2ACVHs0MZgniZ4Go9csTPnnCda-aSF24a0E-W9vt0Gxij68JM2iN_JTnt9x8_kQcyw2iFGlxGZewbCH9IL0rvPbq4Cy0ZvzmRTmjzTzzErj8Rt7WolpjC5_3uc2E5BVgLvJAf4bak-L-Lius4/w400-h206/Screenshot%202023-10-17%20124529.png\" alt=\"Timer appears in the upper left corner, but it could be placed anywhere, or appear on demand.\" width=\"400\" height=\"206\" border=\"0\" data-original-height=\"749\" data-original-width=\"1454\" data-is-external-image=\"true\"><figcaption>Capture from a rabbit counting experience. The timer appears in the upper left corner indicating 33 seconds left. Timers and clocks can be placed anywhere in XR.¬†</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Combining what we already know from the Multimedia Principles will maximize the opportunity to learn <strong>by placing the relevant information when and where the learner will need it.</strong></p>\n<p class=\"article-editor-content__paragraph\">Starting with real world correlations is the healthy first step, but next, the IDs should consider <strong>what affordances</strong> XR can further provide. For example, do the learners need to fly or go inside an object? XR easily provides the ability to go through what would be solid objects like walls. Referring to a prior example, if a learner needs access to a clock, can a floating one be put into the learner's field of view, but not necessarily on a wall or wrist? By imagining the experience in pieces or segments, an ID can deconstruct what is necessary to drive the experience along and then rebuild those segments with the added possibilities of 3D design.</p>\n<p class=\"article-editor-content__paragraph\">Here is another example: an experience is replicating a spacewalk in outer space. The learning objective is to have the learner follow the correct procedure despite stressful conditions. The learner needs to put on a space suit following the correct procedure and check it for safety before leaving the spaceship. The emotional tone is to be calm and methodical even if the situation is urgent. What is the real world correlation to this experience? It might be donning protective equipment at a cold weather research station. This is a cognitively correlated event; the thought process is very similar. Thus, we can use this real world event to drive the design of the XR event. Items need to be put on in a certain order and checked for safety before going outside.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjvt9JlQwiqcho6h3WDMbjYvHX6DhO9RAkJU51CAfw0FUFid1Nx6__Wy8mScv807osQNHpQdETh7LwJ1KQBetjzJRQLl4YOncIJqsVMpXlblwC6PbwT9lncp0nsred-Keo-q6wTVathUDMETGUvvh5GIA4gRGwGzylDG8UJbYaLM-bk1ToC-SijFepAX6U/w640-h360/Analogous%20experiences.png\" alt=\"Graphic with text: Analogous experiences showing that protective clothing for astronauts and Antarctic visitors are similar. Therefore, we could use the latter to help build XR instructions for the former.\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"1080\" data-original-width=\"1920\" data-is-external-image=\"true\"><figcaption>Bundle up, baby, it's cold outside.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">The XR design might want to include an alarm sound or flashing light to create urgency. Some sort of ‚Äòbuddy check‚Äô system might stand by so that after the learner puts on the equipment, it is checked by another entity. Including alarms and safety checks are correlations to real world elements that can be built into the experience<i>.</i> The details of surrounding walls and floors or what is happening outside the spaceship do not influence this learning event. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\" rel=\"noopener noreferrer\">Mayer</a> (2020) refers to these as <strong>seductive details</strong> ‚Äì interesting, but they detract from the learning. Therefore, those details can be minimized in the surrounding design.</p>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p class=\"article-editor-content__paragraph\">Part 8 is the last part!! It will acknowledge the limitations of what we know from research so far. But I've tucked one of my best tips into Part 8 before I conclude. Stay tuned, fellow babies*, for one last time.</p>\n<figure class=\"post__image\" ><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/ID-in-the-Meta-Part-7.png\" alt=\"\" width=\"2240\" height=\"1260\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/responsive/ID-in-the-Meta-Part-7-2xl.png 1920w\">\n<figcaption >Decorative image: Prompt: Wide angle shot from the side, in the style of full color charcoal and Legend of Zelda game cover art, a female profile in a hooded cloak climbing up a mountain towards light, she carries a flame in one hand, in the style of deep indigo, light silver, enchanting lighting, blue and green color scheme --ar 16:9¬†</figcaption>\n</figure>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-1.html\" rel=\"noopener noreferrer\">Part 1</a> was the Introduction.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-2.html\" rel=\"noopener noreferrer\">Part 2</a> covered Theory and Scope.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part.html\" rel=\"noopener noreferrer\">Part 3</a> was Myths versus Reality.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_8.html\" rel=\"noopener noreferrer\">Part 4</a> covered the Characteristics of Success.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_10.html\" rel=\"noopener noreferrer\">Part 5</a> was What is the same between 2D and 3D design?</p>\n<p class=\"article-editor-content__paragraph\"><a href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_02074647801.html\">Part 6 </a>was What is different between 2D and 3D design?</p>\n<p class=\"article-editor-content__paragraph\">Want to see my full references? <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse.html\" rel=\"noopener noreferrer\">Have at it</a>.</p>\n<p class=\"article-editor-content__paragraph\">*Apologies if you don't catch the reference to <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://en.wikipedia.org/wiki/Dr._Johnny_Fever\" rel=\"noopener noreferrer\">Johnny Fever from WKRP</a> where groups of people were \"fellow babies\".</p>\n<hr>\n<p class=\"article-editor-content__paragraph\">##InstructionalDesign #XR #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #Approach #LearnerCentric #NarrativePlot #Storytelling #Purpose #Design #Emotion #PrinciplesOfDesign #RealWorld #Correlation #edtech #DonNorman #GuyWallace</p>\n<p class=\"article-editor-content__paragraph\">¬†</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/696/Part-7.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-20T13:52:00-04:00",
            "date_modified": "2025-08-02T15:37:17-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-6-what-is-different.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-6-what-is-different.html",
            "title": "Instructional Design in the Metaverse Part 6 What is Different?",
            "summary": "Welcome to Part 6! Are you alive? By my calculation, when this goes live, 3 intrepid souls have read all of Parts 1-5 before this. (Insert laughter with tears üòÖ). Indeed, you may have found this in isolation of the other parts! That's OK, I'm&hellip;",
            "content_html": "<div class=\"separator\" style=\"clear: both; text-align: center;\">¬†</div>\n<p class=\"article-editor-content__paragraph\">Welcome to Part 6! Are you alive? By my calculation, when this goes live, 3 intrepid souls have read all of Parts 1-5 before this. (Insert laughter with tears üòÖ). Indeed, you may have found this in isolation of the other parts! That's OK, I'm cool with modularization. Feel free to \"go around the Horn\" at some other point in the future and read Parts 1-5 later.</p>\n<p class=\"article-editor-content__paragraph\">Oh! And, for those 3 travelers AND everyone else, I am making an explainer video of all of this content. But it comes with 2 caveats:</p>\n<ol class=\"article-editor-content__ordered-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">No references or quotes. Just ideas.</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Because it moves with a preset piece of music, each idea will have a limited amount of screen time: 2.4 seconds, to be precise.</p>\n</li>\n</ol>\n<p class=\"article-editor-content__paragraph\">Finally, I'll probably write a full BTS (Behind The Scenes) on this article series. For those of you that love BTS content, that one will be for you. Translation: these articles were NOT written to be sound-bite worthy.¬† What I write in the BTS will be.</p>\n<p class=\"article-editor-content__paragraph\">This is basically the second of two parts that were originally together: Part 5 is what is the SAME about designing between 2D and 3D and this is what is different.</p>\n<p class=\"article-editor-content__paragraph\">Long story short?</p>\n<p class=\"article-editor-content__paragraph\">Here is where the fun begins.</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjqbKIipta0O-oUgy9seGBDzNBEe4PGDGJkr8ICfhyuyjr-3bCEr4pAlwZDWkcqXPN4CZwoFRRmENtP3fRF90DRv7I1TEPi2VlF18eZMD6JdZvXye0pjatz45akoW4vW2Iro4M1bZ135ap1Gtu8zFYrt_WKOwFjEPQe_-FtL7EyvSTYM1N9cZk0m_c5bjE/s498/fun-this-is-where-the-fun-begins-3562248195.gif\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/fun-this-is-where-the-fun-begins-3562248195.gif\" alt=\"Gif of Anakin Skywalker saying This is where the fun begins.\" width=\"320\" height=\"254\" border=\"0\"></a></div>\n<h2 class=\"article-editor-content__heading\">2D to 3D: What Is Different</h2>\n<p class=\"article-editor-content__paragraph\">A learner could learn from a book how to enter a store and buy something. A learner could also learn from entering a real store and buying something. Both are ways to complete the learning, but the designs‚Äì that is, how to structure the learning from start to finish, will be different. The book is analogous to direct instruction. There are times when direct instruction will be the better approach. The real store is analogous to experiential learning. There are times when experiential learning will be the better approach. The approaches are different; there is no inherently better approach for all situations.¬†¬†</p>\n<p class=\"article-editor-content__paragraph\">These elements in this section are not meant to imply that they exclusively belong to XR media. That is, many other forms of media contain these same elements. These items are listed here because they are often found within and indeed<i> are combined</i> in design solutions in XR.</p>\n<h3 class=\"article-editor-content__heading\">1 Narrative Plot</h3>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=v1uzCgAAQBAJ&amp;lpg=PR17&amp;ots=TNCJkGdMdm&amp;dq=clark%20mayer&amp;lr&amp;pg=PR17#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">Clark and Mayer</a> observed that humans are sense makers and attempt to derive meaning from life experiences (2016). Learners engage in making meaningful connections when words and pictures align during experiences. Meaning is also deeply embedded in the storytelling approach, where it is often the journey that the protagonist goes through that remains memorable long after a story has ended. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=PXRJEAAAQBAJ&amp;lpg=PP1&amp;ots=UpbIsA4SJU&amp;dq=learning%20experience%20design%20Clark&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">D. Clark</a> argued, ‚Äúlearning experiences are exactly that, experiences designed to change us, specifically our long term memories‚Äù (2022, p. 7). Further, D. Clark advocated for a balanced use of storytelling, explaining that it can bring life to dry information, but should not be overused and wander into a ‚ÄúDisneyfication of learning as entertainment‚Äù (2022, p. 7). Lastly, D. Clark argued that stories for learning should be designed as ‚Äúalways beginnings, never ends-in-themselves‚Äù if the learning is to be applicable beyond the experience, into the ‚Äúlong tail of practice, transfer, and performance‚Äù (2022, p. 7).</p>\n<p class=\"article-editor-content__paragraph\">Points for poetry, D. Clark!¬†</p>\n<blockquote>¬†‚Äúalways beginnings, never ends-in-themselves‚Äù</blockquote>\n<p>¬†</p>\n<div class=\"separator align-left\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjX6PaSD29tfvnr7BdTm3VugUb83udyPwOOxQ6W2TCyNPiWiMsv1NPTY9lKWIjfVkY_BXmh9dIo_8yznVXj55ak8b03rgE3RFXVtHjZL1506Z_s_6wZ21F40SqqFz8Jg62jYQ5R8EIGLHKYCc2UJJNw4KYdFMEQ9dfz4BF_20mnaitls-z-HU_pCY8a3Ds/s1456/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b.png\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b.png\" alt=\"Decorative Image: Our metaverse explorer is exchanging stories with other storytellers.\" width=\"640\" height=\"358\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_in_cinematic_style_enchantment_a_storyteller_with_d90ac9bf-70a7-47b4-9d52-d352d93d975b-2xl.png 1920w\"><figcaption>Humans crave stories that bring meaning¬†</figcaption></figure>\n</a></div>\n<p class=\"article-editor-content__paragraph\">Indeed, the storytelling approach in learning pulls the learner through the experience. To use storytelling, the learner should experience a flow through their experience, a beginning and middle of the story. The end could happen in XR or more substantially outside of XR into desired application. The learning experience <strong>should be planned and not haphazard.</strong> Learners should be guided on a planned route. XR storytelling can be first person or group experiences. Regardless, each learner is a protagonist; their decisions determine what they will experience. Recalling the constructivist learning theory foundation, what the learners <i>experience</i> becomes the learning experience that is being designed <i>for</i>. If learners are exposed to situations where they actively construct their knowledge, then the reality that the learners construct was constructed <i>by them</i>, not constructed by the media or by others. Further, learners do not arrive as empty vessels to be passively filled with information if they are the protagonists of their own learning event. Learners add, sort, emphasize, or suppress new experiences when compared to old experiences.¬† Subsequently, a learner already experienced in real life (non-XR) is bringing those experiences into XR with them. In summary, <strong>learners arrive already ready to experience a story. Thus, narrative plot or a story arc is a good approach to XR instructional design.</strong></p>\n<p class=\"article-editor-content__paragraph\">Plot, narrative, or narrative plot are all descriptions of phases within storytelling. There are slight variances in names but the phases generally focus on the user‚Äôs (or in our case, the learner‚Äôs) experience (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=DHo3DwAAQBAJ&amp;lpg=PP1&amp;ots=mZnAwii8NJ&amp;dq=Lichaw%2C%20D.%20(2016).%20The%20user's%20journey%3A%20Storymapping%20projects%20that%20people%20love.%20New%20York%3A%20Rosenfeld%20Media&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">Lichaw</a>, 2016).¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEib7_Z17dgwlIEih2h-Rhv3XOX7XYZ_Moopn1pT_lo1hyHKkrhZ3QqDXcJH4mdCn-JyrG8vVZi31NSozmigpSIt9n_9XNR1lnZeq_LA6h3oHImQJGt_Hvqx9ZnR17C1KH4JHOb_YTvLV_0qkDMYJjQ1FBvLJlagV5n2jJd_jt6rqcROf_54OQqBeoE_uVA/w640-h406/Narrative%20plot%20Lichaw.png\" alt=\"Narrative Plot steps from Lichaw: Exposition, Inciting incident,  Rising action, Crisis, Climax, Denoument, End.\" width=\"640\" height=\"406\" border=\"0\" data-original-height=\"886\" data-original-width=\"1400\" data-is-external-image=\"true\"><figcaption>If you remember nothing else about designing educational XR, remember this.¬†¬†Credit: Lichaw, 2016.</figcaption></figure>\n<p>¬†</p>\n<p class=\"article-editor-content__paragraph\">These phases describe what is happening to the protagonist. In the case of XR, the learner is the star and they should be brought through these phases in an effective design plan. Table 1 compares a storytelling arc with the Pixar story arc, a story arc example of Cinderella, an XR story arc, and an XR narrative plot example.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxSOF9gbn39Qj1xwvfMionIyF3hUlJfCENY_ftmNl5rYvZMy6Ywjy7ga3S3gmFKOUDmaZGAiHFtoWeXA3Ae7MpeLHwyHIpHrVUEVU1PrXn2lObTT3lEcfg-IYIMtRx1LT-_BoMLcO9ZRTCCAvJJPhig0Ymej6MhpAElU3xdBf3NOmuDbqQYB50PvAKyvM/w640-h480/Narrative%20Plot%20Table(1).png\" alt=\"Examples of the storytelling arc of 6 steps: Literary, Pixar, Cinderella, XR template, and XR example\" width=\"640\" height=\"480\" border=\"0\" data-original-height=\"768\" data-original-width=\"1024\" data-is-external-image=\"true\"><figcaption>Examples of the storytelling arc of 6 steps: Literary, Pixar, Cinderella, XR template, and XR example.¬†<br>Pixar story arc from Khan Academy. (2017). <i>Pixar in a box: Introduction to storytelling</i> [Video]. YouTube. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://youtu.be/1rMnzNZkIX0\" rel=\"noopener noreferrer\">https://youtu.be/1rMnzNZkIX0</a> Cinderella story arc derived from Kurt Vonnegut, as documented by Derek Sivers. (2009, September 1). <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://sive.rs/drama\" rel=\"noopener noreferrer\">https://sive.rs/drama</a></figcaption></figure>\n<h3 class=\"article-editor-content__heading\">Example of Narrative Plot in XR</h3>\n<p class=\"article-editor-content__paragraph\"><strong>Introduction.</strong> The who, what, where, why, when of the experience is explained. The scene opens. This starts before the digital experience begins and lasts 30 seconds to a few minutes into the experience, depending on how much needs to be explained. This is the beginning of the exposition.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Set the scene. </strong>Provide guidance on the affordances within the experience, how to communicate, walk, navigate, where is help (e.g. where is a digital companion). The learner is invited to move, change appearance, and communicate.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Dilemma.</strong> Introduce the conflict or the scenario that the learner will participate in. The learner is presented with a challenge or problem. This is the inciting incident and rising action phases. This can be a great time to guide and practice small solutions to small problems.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Crisis.</strong> The learner must act and initiate some sort of change. It is action-oriented, and the learner is on center stage.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Change or Denouement.</strong> The results of the change have an impact on consequences or the environment. Said another way, the change ripples through the experience to change it for the learner. The results are non-trivial and not haphazard.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Resolution or End.</strong> The mission is complete, and the world has changed around the learner. The learner is living out the consequences of their decision.</p>\n<p class=\"article-editor-content__paragraph\">Some research has shown that most of the instructional emphasis does not need to be within the XR experience itself. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.youtube.com/live/l3tw6O8Hn-s?feature=share&amp;t=1663\" rel=\"noopener noreferrer\">Dede</a> (2021), when reflecting on what he now believes after over five decades of immersive learning research, said:</p>\n<p class=\"article-editor-content__paragraph\">‚ÄúI used to believe that if you had resources, you should spend 95% of the resources on the immersive experience and then you just do a little thinking about what kind of induction you use before people go into immersion and what kind of post experience debriefing you do.¬† I‚Äôve come to believe now that the induction and debriefing is where the learning takes place predominantly, and so designing those is very important.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">This indicates the importance of the on-boarding and the follow up experiences. The story of an experience begins before something is activated and ends long after.</p>\n<p class=\"article-editor-content__paragraph\"><strong>The main point of keeping a narrative plot mindset in ID XR design is to keep the learner at the center of the experience. </strong>Every step of the narrative plot approach focuses on what the protagonist- that is, the learner- experiences: dilemmas, crisis, change, etc. This approach, then, keeps the ID focused on the learner‚Äôs experience, not the technology. For example, let‚Äôs say a platform can recreate the school environment down to the desks and chairs. An ID might reason, ‚ÄòThis a great place to hold a class! I can assign classes to virtual rooms and the instructor can use web-sharing boards.‚Äô¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZXncQoR6J1Wug8PH_6xKWKZyZ772q3k-w61ChXyhfwngenGGeu2UOf84fgF22mDaQ60YKCspz5N6SJFxJw39YPoKI7ZTg799qmVTW_CE1bl9bnrfgJbl8B-ztIKbX-wPeo_Ev640ahyphenhyphen0Gw0bTa0Q046FAS2sCALYMk4pP7aC7d1C-nTrmXuYGxjphUxM/w640-h354/virtual%20reality%20classroom.png\" alt=\"Capture of a classroom in virtual reality, complete with desks, chairs, and chalkboard.\" width=\"640\" height=\"354\" border=\"0\" data-original-height=\"757\" data-original-width=\"1366\" data-is-external-image=\"true\"><figcaption>Don't try this in VR</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">That approach puts the technology first and does not consider the learner. It also recreates the problems of regular in-person classrooms and throws in a few more virtual problems as well (i.e., poor internet connections might have avatars distractedly appearing and disappearing). Rather, a learner-centric approach might ask ‚ÄúWhat is the main experience or emotion that the instructor wants the learners to have in this lesson?‚Äù As <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\" rel=\"noopener noreferrer\">Mayer</a> stated, ‚ÄúHow can we adapt multimedia technology to <i>aid </i>human cognition?‚Äù (2020, p. 15). This might cause the ID to look at the entire XR event differently and not recommend a virtual classroom. There is more on emotion in design in Section 5.2.</p>\n<figure class=\"article-editor-content__figure-image\"><figure class=\"article-editor-content__figure-image-caption\"><img loading=\"lazy\" <figcaption ></figure></figcaption>\n<figcaption class=\"article-editor-content__figure-image-caption\">\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhvbmd4Pa8tXVctxz3yU-YbTV1T9SYhrmgiC-7Kv67PNs-pXV4llNMp4Amvbk9zNOsy4Jj5Lme_YE7CYp-fn__PMqFzyAf45FMgTFQsZmglzgFc5PSR3AUA2_WD_DQPIadDPAqbtnjcs_CxAYq9hQKmAP1nVcI-w2TqWM5s9iJ9RZSHEGousEvb_fFdI38/s1200/lord-of-the-rings-timeline.jpg\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/lord-of-the-rings-timeline.jpg\" alt=\"Lord of the Rings Narrative Plot Diagram. Basical huge spaghetti.\" width=\"640\" height=\"336\" border=\"0\"> sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-xs.jpg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-sm.jpg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-md.jpg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-lg.jpg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-xl.jpg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/lord-of-the-rings-timeline-2xl.jpg 1920w\"></a></div>\n<p>¬†Credit: https://fbvisualisation.blogspot.com/2014/04/narrative-charts-tell-tale.html</p>\n</figcaption>\n<figcaption class=\"article-editor-content__figure-image-caption\"></figcaption>\n</figure>\n<h3 class=\"article-editor-content__heading\">2 Visual and Sound Range</h3>\n<p class=\"article-editor-content__paragraph\">For the ID, the added visual depth and sound possibilities beyond 2D must be designed. However, more to design means more risk. With XR, the added ability to put information anywhere has more risk of overwhelming the learner than helping the learner. Indeed, D. Clark (2022) agrees that Mayer‚Äôs Principles lean towards <strong>less is more</strong>.</p>\n<h3 class=\"article-editor-content__heading\">2.1 Visuals</h3>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://aperturesciencellc.com/vr/VisualDesignMethodsforVR_MikeAlger.pdf\" rel=\"noopener noreferrer\">Alger</a> (2015) noted these basic principles for visual range called the Comfortable Content Zone: 77 degrees of viewing range side to side and a range of 0.5 to 20 meters in depth. There are Periphery Zones to the sides and above, but the learner should be only prompted to use those.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiXlCGMsk_cHdRuq4D9ZKPbgl5DEVXSMv7cehq-y8HfE0xdTrI4nTFh6UZ9SNg4ezMLhusTnsIhuYbZJWTd8uX83DNW85bMlvIrg2MoAab5xZ-AVmROSTnq02oTfoPBjUPYq3yCMwa0ACm2okNvey03RPUSUKc4AUpxgGMf03JOzoqnZ61vKFdbpUmQJXo/w640-h328/Mike%20Alger%202.png\" alt=\"Diagram showing that main content should be placed between 0.5m and 20m to the front of the user. The sides are the peripheral zone and the back/behind is the curiosity zone. Anything within 0.5 of the user is the no-no zone, meaning put nothing there.\" width=\"640\" height=\"328\" border=\"0\" data-original-height=\"779\" data-original-width=\"1522\" data-is-external-image=\"true\"><figcaption>Credit: Alger, 2015</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">This reflects real life. If one was working at a workstation, critical information would be within easy viewing and reach. Other information could be available in what Alger calls the Curiosity Zone ‚Äì behind and below the learner, but learners should be prompted, as in real life, by sound, light, or foreknowledge, to engage with that non-obvious space (2015).</p>\n<p class=\"article-editor-content__paragraph\">Alger (2015) further proposes that the visual hierarchy matches the importance of information. To find information in 3D, we look at the center ahead first, then left and right, then below, then above, then finally at our own bodies. Everything above eye level is for things beyond the learner‚Äôs control like weather, time, or authority notifications. Everything at or below eye level is within the learner‚Äôs control.</p>\n<figure class=\"align-center\" ><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjgPd-Nq_165ZKbiDQJxV16oX1rcCKGiAhmEMRaqShworqsfFJXlkYwwuTpokKZYL4zun6Qb-s7ChXOEiqID1g-RkuRCGJVxSac_rQ4NaQD2l-I8d6aesK3g3hGVDyjQDv4eYWCfAmb4nFqBkmoTc7v3XcZblx_WacAxH9Hhe9Wrs1kom-nwmQWGHmXC9g/w320-h320/LinkedIn%20Post%20Mike%20Alger(2).gif\" alt=\"Caption describes gif.\" width=\"320\" height=\"320\" border=\"0\" data-original-height=\"900\" data-original-width=\"900\" data-is-external-image=\"true\"></figure>\n<figcaption >Basic visualization of where a VR user <i>would</i> look for something; first center ahead, then left and right, then above and finally at the user's own body.</figcaption>\n</figure>\n<p class=\"article-editor-content__paragraph\">These user interface principles skew towards conservatism in detail; less is better. IDs should design minimal spaces, with prompts, and within easy arm reach. IDs can create storyboards with isomorphic qualities that both curve around the learner and contain planning space for the foreground, mid-ground, and background visuals.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiIZXzEDc8hv67SXDNmz_lbD6gwTQOJrCPUd0ppq3KU67Dp8VD8gkkKpNfTMHBuylHVeBMtakW7Z88l2Y8nm4xOsFe7pvSRDiZG5mzXO9Ew8LnVzvVxltqXQr3OtYQ4zwcZfMe02lS2NV1p9DpPzHld4zNHJ5WpPzuPVqezcGYvnYLC1CfTSojJPM-UCZg/w320-h288/Mike%20Alger%208.png\" alt=\"Capture showing how designs expand between foreground, midground and background.\" width=\"320\" height=\"288\" border=\"0\" data-original-height=\"779\" data-original-width=\"866\" data-is-external-image=\"true\"><figcaption>Credit: Alger, 2015.</figcaption></figure>\n<p>Credit for below: <a class=\"article-editor-content__link article-editor-content__link\" href=\"http://ExperienceDynamics.com\" rel=\"noopener noreferrer\">ExperienceDynamics.com</a> but I received these XR storyboards from the Interaction Design Foundation.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgxpQ2AIbH43GN1h043L0gql_gJYnbbhVqP1a8f3WHnrtRT8BZ-JEjEYnOtlZwbGu4Ev1uy3zU0juO7kVfoJGXNUe1utg48XkUm6u16Zzc_Mo6bJLhQXI5zq9xizJ_qz9IXYq_4hVtVciMXDe0HkpE0acDFKJluM7Q_FhoMehIYysRoAbg82pNIM3Oe1pk/w320-h219/storyboard%20by%20scene.png\" alt=\"XR Storyboards showing 3 blank scenes\" width=\"320\" height=\"219\" border=\"0\" data-original-height=\"653\" data-original-width=\"953\" data-is-external-image=\"true\"><figcaption>XR Storyboards showing 3 blank scenes</figcaption></figure>\n<p class=\"align-left\">XR storyboards, blank and capable of showing 3 scenes; the idea might be <strong>one scene per step in narrative plot.</strong></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjwknijhw0-22K0xby27LN8DOrQfeu3iMsnfsQJidh36rs_TlndvCK4yQHnB1JymUEzoQS4ACHS47iiASKxeIYr0UXxySvpIOaMarJLLssJ3ksvEOdHFTlcCV1YeHafiG9FHbPx7L70GiaDns_97_etnhvcx4wP1aJEl1_iynSuh2fIhTo_VTostq4RqdM/w320-h184/storyboard%20templates%201.png\" alt=\"A center grid pattern has 4 rectangular grids out in front showing design spaces to use in XR around a user.\" width=\"320\" height=\"184\" border=\"0\" data-original-height=\"785\" data-original-width=\"1365\" data-is-external-image=\"true\"><figcaption>A center grid pattern has 4 rectangular grids out in front showing design spaces to use in XR around a user.</figcaption></figure>\n<p>Another type of XR storyboard; this showing 4 possible areas for the user to look at.</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgAuvlLjoDcAk9_IzqpgRGubagfz6EkH5zzH0uTMa8JoKH1GKxjMZvQ57HrUaMd6A8GzET6aAr3V1zZDkMYoi5lFmdMRUJxkd_v0n9eLWvAODJ5u69sJD9JL46Q_C30N_R0fQfi4xuBPNrLHFgleiOZ7lt3NFvcLdeLp-FJdzNP-EIqMjgIZSVS0TuKjHY/s700/storyboard.png\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/storyboard.png\" alt=\"Single scene XR Storyboard, emphasis on zones around the user.\" width=\"320\" height=\"234\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/storyboard-2xl.png 1920w\"><figcaption>A single XR scene storyboard. Emphasis on the zones around the user.</figcaption></figure>\n</a></div>\n<h3 class=\"article-editor-content__heading\">2.2 Sound</h3>\n<p class=\"article-editor-content__paragraph\">Immersive sound is a rising field within XR design. Poor sound can ruin an XR experience. Experiences can have <strong>spatial sound</strong> where the loudness drops off over virtual distance or <strong>flat sound</strong> where the loudness is the same throughout the entire space. As much as possible, it is good accessible practice that <strong>all senses should have learner controls</strong>: brightness, sound, movement, and intensity.¬†</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhBqUl49v-gCf22SBsEglRaA7fJ-IpSZ3AjvEVFz1jnz45gxmxxg2JMyHKlQhQZUUh9hTxQSj5CRRXdyWNCk57ZJm8ZqrLMsE1rr0P3lCb0q9wn5GpmcPhJdw5yb8ReStgtkDck0Wpu1kFXOSPpTeWwWskO2HELQdUxBBvalp5uNy0gEt8iNUkUUSSFfBA/s1024/cosmonious-high-vision-accessibility-update-1024x576-1458925651.jpeg\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/cosmonious-high-vision-accessibility-update-1024x576-1458925651.jpeg\" alt=\"Capture of inside Cosmonius High game showing more accessibility features that users can select.\" width=\"320\" height=\"180\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-xs.jpeg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-sm.jpeg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-md.jpeg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-lg.jpeg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-xl.jpeg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/cosmonious-high-vision-accessibility-update-1024x576-1458925651-2xl.jpeg 1920w\"></a></div>\n<p class=\"article-editor-content__paragraph\">After Cosmonious High from Owlchemy Labs did some vision updates, they had over 1.53 million times users put their hand over an object to request text-to-speech--in one month and only with Quest users. Still think accessibility features are optional?</p>\n<p class=\"article-editor-content__paragraph\">Many platforms and experiences already contain volume controls for separate parts of the experience (e.g., voice chat, environment, or notifications all have separate volume controls). Learners should be trained on these controls at on-boarding.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhIoY1ckmx7Kp1Iz98azjJ3-l8KCAtrMSs7ogVLugIKlF1CivfuUx4hUGYtM6ll6UxkrwL9xdflfqtGjOYXNmraN-3RmepvkqrUcSxHR_-HnB1BrOGqDEnepdEkydQBp9ktx8Qm7G5b5PyMl9rTNtxfNKM0L2I3swfaYkhqUqOi1a7Va5fOwlJPsd_OtYg/w320-h270/Cosmonius%20High%20accessibility%20sound%20text.png\" alt=\"Capture from inside Cosmonious High game showing accessibility features\" width=\"320\" height=\"270\" border=\"0\" data-original-height=\"1273\" data-original-width=\"1509\" data-is-external-image=\"true\"><figcaption>Cosmonious High capture of some accessibility settings. Note that only one hand is needed to play this VR game.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Generally, for information that is necessary for the learning event:</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">If the information is in speech, provide text equivalents (e.g., transcript).</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">If the information is in sound (environmental sounds or notifications), it should have equivalent visual and/or text indicators.</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">If the information is in text only, provide sound equivalents.</p>\n</li>\n</ul>\n<h3 class=\"article-editor-content__heading\">2.3 Interaction &amp; Movement</h3>\n<p class=\"article-editor-content__paragraph\">Interactions in XR could be reaching, grabbing, and moving. Good experimental research exists from organizations like <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://ieeevr.org/\" rel=\"noopener noreferrer\">IEEE VR</a> or <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://iui.acm.org/2024/index.html\" rel=\"noopener noreferrer\">ACM IUI</a> on 3D user interface recommendations. Alger‚Äôs (2015) design advice showed a seated avatar seated work will be more comfortable than standing in XR.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEivAIDkUkL9l7ilOq52s0sm-xU_k16cknx9h7MgKZTjyz2fnvlxoaRJvM9xt7E6En-mRoxMbDltFjf8Rfst-SwDwdMYjBGdxAUfirFe2S51vlv7PA52q14oNKKdgOWd8yIzteqkFfwatiBEff_Y84HOlzzXUNetHzZKrkCXJ3yhvWv6hV_URVhCCmuFINE/w640-h562/Mike%20Alger%205%20zones.png\" alt=\"See Mike Alger's 2015 thesis for more but these images show where a user can be reasonably be asked to reach or gesture.\" width=\"640\" height=\"562\" border=\"0\" data-original-height=\"930\" data-original-width=\"1060\" data-is-external-image=\"true\"><figcaption>Alger, 2015.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Almost every new XR user has walked their avatar into a wall. It happens.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhP-w38jE54vtgDNf5mkFrPrh32EnjmGyyInAPf4oD83J0Y1K7nTaQLpBLErGZtE78uA72g-pD1zvrs8arJZXeiPTmeHavuEOH8g2VXwfNpNqeH9-WvUzjW9FkS7M2VTq1fVsMICpKAK7rqqGSU3fmGlvzrfi3wTRO_SWIwo0r6BpooU6zI8Pckc1mHVa8/w400-h308/Peter%20must%20stand%20in%20the%20corner%20after%20the%20Workshop%20meeting.png\" alt=\"Capture of my friend Peter when he walked his avatar into a corner.\" width=\"400\" height=\"308\" border=\"0\" data-original-height=\"726\" data-original-width=\"946\" data-is-external-image=\"true\"><figcaption>You stay in that corner until you can act like a good avatar, Peter!</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Given that the wall isn‚Äôt real, mistakes like this are forgiven quickly. IDs can ask learners to move.¬†</p>\n<p class=\"article-editor-content__paragraph\">(And Peter knew I took his picture at this moment above.)</p>\n<p class=\"article-editor-content__paragraph\">Movement in XR is an advantage of the metaverse. While research does not indicate that movement causes learning, it can greatly assist in the storytelling aspect of bringing a learner through an experience by requesting that the avatar move <i>through the story</i> in virtual space time.</p>\n<p class=\"article-editor-content__paragraph\">Movement is <i>relative</i> in this media. Frame of reference can be manipulated. The avatar can move, or the avatar can stay in one place and the scenes can move or change around them. There are a LOT of <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.tomshardware.com/picturestory/807-virtual-reality-games-locomotion-methods.html\" rel=\"noopener noreferrer\">choices for movement in XR</a>. From gaming research, it looks like most of the possibilities are aiming to reduce vestibular mismatch.</p>\n<p class=\"article-editor-content__paragraph\">In this area, movement-based engagement can be an area of exploration in designs. For example, asking learners to move to one side of the room or another is an interesting way to run a poll. XR movement often includes dancing and flying. Future research should explore the use of controllers or hand detection for learning.</p>\n<h3 class=\"article-editor-content__heading\">2.4 Emojis</h3>\n<p class=\"article-editor-content__paragraph\">Many social XR platforms have incorporated emojis and they can be used for their apparent reasons: love, happy, sad, clapping, or raised hand. Within designs, learners can use them differently, that is for feedback, poll indicators, or silent ‚ÄòI need help‚Äô indicators. Learners have been known to redefine emojis to mean whatever makes sense to them during a learning event.</p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhX6Lklsgk73sRtkPk4Wv6k40DDqkilg2uh1HOUcXF_CbkEkWV7hldIN1NM27U8HMaSTL1mzT7PWD2pocq0UhdoY1k-GPAY8LP0aGCH8OrwMEGJ41cZTcbaBbLkYkFqxzVQadnV-xP_vcy25aWr1VN86dmwFusmMuc9lVQ8GGPPHo5FPsR9auVcpAuR7Bk/s600/relle2020-02-22_12-42-01.jpg\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/relle2020-02-22_12-42-01.jpg\" alt=\"Capture of a great moment from the start of the International Summit of Educators in VR. Each avatar chose to express a heart/love emoji.\" width=\"400\" height=\"286\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-xs.jpg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-sm.jpg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-md.jpg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-lg.jpg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-xl.jpg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/relle2020-02-22_12-42-01-2xl.jpg 1920w\"></a></div>\n<p>¬†Cheers to Educators in VR for their use of emojis during their International Summit in 2020.¬†Part 7 will cover designing and building XR experiences for learning. See you there!</p>\n<hr>\n<p><br><a name=\"more\"></a>¬†<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-1.html\" rel=\"noopener noreferrer\">Part 1</a> was the Introduction.</p>\n<p><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-2.html\" rel=\"noopener noreferrer\">Part 2</a> covered Theory and Scope.</p>\n<p><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part.html\" rel=\"noopener noreferrer\">Part 3</a> was Myths versus Reality.</p>\n<p><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_8.html\" rel=\"noopener noreferrer\">Part 4</a> covered the Characteristics of Success.<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_10.html\" rel=\"noopener noreferrer\"></a></p>\n<p><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_10.html\" rel=\"noopener noreferrer\">Part 5</a> was What is the same between 2D and 3D design?</p>\n<p>Want to see my full references? <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse.html\" rel=\"noopener noreferrer\">Have at it</a>.</p>\n<p><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiA_nfjqBD9QWPmQORXVU6vzL9Uh03laNFC9VZYN7Kt_GG7naBYby3NG0-iohzhe-Fq6auRgKlerygpipCB6gOHy2G_7jYIfnz9Ni2EOxkGUx-nA0s4gtEru8LgISLWn4MHCUjv-xa8e0NQKKaGx25plDv_wYX9PBpPN7chRnrhUaQRMKHTsIkik-2MKVw/s1456/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336.png\" alt=\"Decorative image of our explorer heading out from the library and laboratory now with the glow of knowledge within her.\" width=\"640\" height=\"358\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/responsive/heather_dodds_Side_view_in_the_style_of_full_color_charcol_and__a0cf9452-0233-4b7e-98bf-f328dc3cb336-2xl.png 1920w\"></a></p>\n<p class=\"article-editor-content__paragraph\">#InstructionalDesign #Metaverse #XR #InstructionalMethod #DirectInstruction #ExperientialLearning #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #ImmersiveWeb #Immersion #3D #2D #NarrativePlot #Plot #StoryArc #Storytelling #Pixar #Cinderella #Vonnegut #Introduction #SetTheScene #Dilemma #Crisis #Change #Resolution #LearnerCentric #Protagonist #Visuals #sound #CuriosityZone #ContentZone #PeripheralZone #FlatSound #SpatialSound #teleport #emoji #edtech</p>\n<p class=\"article-editor-content__paragraph\">¬†</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/697/Part-6-What-is-Different.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "XR",
                   "Metaverse"
            ],
            "date_published": "2023-10-15T14:30:00-04:00",
            "date_modified": "2025-08-02T15:26:15-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-5-building-blocks.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-5-building-blocks.html",
            "title": "Instructional Design in the Metaverse Part 5 Building Blocks",
            "summary": "This conceptual series proposes instructional design principles for the metaverse. This is Part 5. Today we start the building blocks of design. And the best news for instructional designers? So much of what we already know from two-dimensional learning will work in three-dimensions. Grab your&hellip;",
            "content_html": "<p class=\"article-editor-content__paragraph\">This conceptual series proposes instructional design principles for the metaverse. This is Part 5. Today we start the building blocks of design. And the best news for instructional designers? So much of what we already know from two-dimensional learning <strong><i>will work</i></strong> in three-dimensions. Grab your toolbox, IDs!</p>\n<h2 class=\"article-editor-content__heading\">2D to 3D: What Is the Same</h2>\n<p class=\"article-editor-content__paragraph\">Technology can benefit learning when the affordances are leveraged towards effective and evidence-based learning principles (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://link.springer.com/article/10.1007/s10648-020-09592-4\" rel=\"noopener noreferrer\">Yeung, Carpenter, &amp; Corral</a>, 2021). Instructional design already has a depth of theory and research that shows that a learning experience is a ‚Äúsystemic, complex design‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Charles-Reigeluth/publication/371304955_How_Do_We_Solve_a_Problem_Like_Media_and_Methods_207/links/647e04b6b3dfd73b7767f1d2/How-Do-We-Solve-a-Problem-Like-Media-and-Methods-207.pdf\" rel=\"noopener noreferrer\">Honebein &amp; Reigeluth</a>, 2023. p. 14).</p>\n<p class=\"article-editor-content__paragraph\">Yet, instructional designers (IDs) interested in the metaverse in education can be at risk for <strong>two unhelpful mindsets</strong>: first, thinking that <strong>IDs must become developers</strong> or second, succumbing to a ‚Äò<strong>buy first, find a use for it later</strong>‚Äô mentality. The first creates a substantial learning curve with the end result mostly being scenes or environments and 3D objects. Currently, AI is able to create scenes and objects (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Chandan-Kumar-Sahu/publication/348037151_Artificial_intelligence_AI_in_augmented_reality_AR-assisted_manufacturing_applications_a_review/links/5fffd7b545851553a0418910/Artificial-intelligence-AI-in-augmented-reality-AR-assisted-manufacturing-applications-a-review.pdf\" rel=\"noopener noreferrer\">Sahu, Young, &amp; Rai</a>, 2021). As a consequence, the need for programmers may decrease. The second mindset leads to IDs to search for educational resources to justify the expense and bother of entering the metaverse.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjeea7qnx2BpCdd1OBqsukeNos2Nv70_t3Lx1BEd5DgsLcKaZF_NAbzZZedXIdCk2eov2t_wX8uVgtbr4MQtXArORUIpfjZKY8jCMnNo_6vzBf-xOmllOase6-DEJBuJkHlcnPyoWvLugDEdkstTatP6biDIFuQuSHXrDxn-G-JbP9BKEvD1LcJPOOPqUw/w640-h142/Buy%20first%201%20blur.png\" alt=\"Capture of a post with text: With the world in such a virtual/hybrid state, I'm curious if any of you have explored using (REDACTED) VR to enhance virtual new hire onboarding experiences. My boss ordered myself and one of my peers our own (REDACTED) devices to explore as this an add on to our current onboarding program, so I'd love to hear from people with similar use cases.\" width=\"640\" height=\"142\" border=\"0\" data-original-height=\"543\" data-original-width=\"2444\" data-is-external-image=\"true\"><figcaption>Buy first, find a use for it later. Technocentric-design.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Both of these mindsets <strong>miss the main point</strong> of instructional design. They sacrifice the <strong>learner-centric stance</strong> for a technology-centric stance (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\" rel=\"noopener noreferrer\">Mayer</a>, 2020). Many of the 2D-based instructional design models, structures, and principles apply towards 3D learning (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://edtechbooks.org/id_highered/immersive_learning_e\" rel=\"noopener noreferrer\">Dodds</a>, 2021).</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">What we already know should inform us as we make future 3D designs because as <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://youtu.be/4o__z7aPlMw\" rel=\"noopener noreferrer\">Alger</a> stated, ‚ÄúPrinciples and processes of design are pretty universal because we're usually designing <strong><i>for humans</i></strong><i>‚Äù</i> (2020, 3:06).</p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">A further extension of this thought would be that IDs are not designing <i>for technology.</i> An ID focusing on 3D design for the first time can have an advantage because their experience will be from a novice‚Äôs viewpoint. Learners are novices. Thus, the ID experiences what the learners will later experience for the first time.</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\"><strong>Keeping the learner-centric point of view is key.</strong></p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">This section emphasizes the use of Mayer‚Äôs Principles of Multimedia Design (Mayer, 2020, pp. 400-402, [Reminder, I covered the basics in <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/instructional-design-metaverse-part-2-heather-dodds-ph-d-\" rel=\"noopener noreferrer\">Part 2</a>]) because they are based on research. This list is not meant as a checklist. This is meant to remind IDs of what the correct design choice <i>would be</i> within a 3D experience.</p>\n<h3 class=\"article-editor-content__heading\">1 Reduce extraneous processing</h3>\n<p class=\"article-editor-content__paragraph\">The Coherence, Signaling, Redundancy, Spatial Contiguity, and Temporal Contiguity Principles will assist in decisions about types of media (visual, text, audio) and where it will be placed or made available in XR experiences. Because of the enveloping nature of the 3D environment upon the learner, extra unnecessary material could interfere with the learning.</p>\n<h3 class=\"article-editor-content__heading\">1.1 Coherence</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúWeed out extraneous material‚Äù.</p>\n<p class=\"article-editor-content__paragraph\">ID: Minimize text, sounds, and movement that is not directly related to the learning goal.</p>\n<h3 class=\"article-editor-content__heading\">1.2 Signaling</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúHighlight important material.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Use slow pulsating glows, arrows, or narrative prompts to focus the learner on the content.</p>\n<h3 class=\"article-editor-content__heading\">1.3 Redundancy</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúDo not add printed text that duplicates narration.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Accessibility concerns dictate that information available via vision or sound should be made available in an alternate form. To follow the spirit of this principle, default settings can be set to include both alternates as activated, which could then be toggled off by the learner at will. XR accessibility research organizations such as <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://xraccess.org\" rel=\"noopener noreferrer\">XR Access</a> or <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://virtualability.org/\" rel=\"noopener noreferrer\">Virtual Ability </a>should be consulted for further guidance.</p>\n<h3 class=\"article-editor-content__heading\">1.4 Spatial Contiguity</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúPlace printed text near to the corresponding part of the graphic.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: There is more space to work with in 3D than 2D. The key with this principle will be to find just the right place to put the text. Some user experience (UX) testing in the form of A/B testing can help find the best placement.</p>\n<h3 class=\"article-editor-content__heading\">1.5 Temporal Contiguity</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúPresent corresponding graphics and narration at the same time.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Sound and action triggers can be timed within 3D programming.</p>\n<h3 class=\"article-editor-content__heading\">2 Managing essential processing</h3>\n<p class=\"article-editor-content__paragraph\">The Segmenting, Pre-training, and Modality Principles help the designer place the necessary material in the right place and time for the learner to move the content into sensory memory, short-term memory, and into long-term memory.</p>\n<h3 class=\"article-editor-content__heading\">2.1 Segmenting</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúBreak a lesson into learner-paced parts.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Plan lessons with storyboards with scenes where the learner moves through the experience. Always provide an escape button that saves learner progress. If that is not possible, a confirmation dialog message can indicate that the learner upon re-entry will be returned to a certain spot.</p>\n<h3 class=\"article-editor-content__heading\">2.2 Pre-training</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúProvide pre-training in the names and characteristics of the key terms.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Plan for pre- and post-experience briefing. Pre-training is analogous to reading the box when considering buying a game or reviewing choices in an online store. The learner experience <i>starts</i> there.</p>\n<h3 class=\"article-editor-content__heading\">2.3 Modality</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúPresent words in spoken form.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Especially for key vocabulary, provide sound files of pronunciation. This especially matters if the experience is designed for solo learner use.</p>\n<h3 class=\"article-editor-content__heading\">3 Fostering generative processing</h3>\n<p class=\"article-editor-content__paragraph\">The Multimedia, Personalization, Voice, Image, Embodiment, Immersion and Generative Activity Principles help encourage learners to cognitively engage with the material and exert effort to make sense of it. It is this area of design where the ID is making sure that the learners are not passively accepting information <strong>but must do mental work with it</strong>.</p>\n<h3 class=\"article-editor-content__heading\">3.1 Multimedia</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúUse corresponding words and graphics to explain the material.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: XR is a natural fit for this principle because it nearly always contains simultaneous visuals and sounds. These can be timed together within 3D programming. An interesting design exercise for IDs, however, is to isolate certain aspects of a design and think through how it might work if only one channel of input was working. For example, in a tour of XR spaces, there might be a period of a few seconds of complete darkness between scenes. How are the learners guided by sound only during this time?</p>\n<h3 class=\"article-editor-content__heading\">3.2 Personalization</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúPut words in conversational language.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Recorded audio should sound comfortably natural.</p>\n<h3 class=\"article-editor-content__heading\">3.3 Voice</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúPresent spoken words in an appealing human voice.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: This applies most logically in XR to human sources of the spoken words. Poor sound can ruin an XR experience.</p>\n<h3 class=\"article-editor-content__heading\">3.4 Image</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúDo not put the instructor‚Äôs static image on the screen.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: The keyword in this principle is ‚Äòstatic‚Äô. This would rarely be needed in XR. Exceptions might include biographies or eulogies.</p>\n<h3 class=\"article-editor-content__heading\">3.5 Embodiment</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúHave instructors display human-like gestures, eye contact, facial expressions, and body movements.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: The Proteus Effect shows that users change their behaviors depending on their avatars (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Daniel-Goerlich/publication/347582766_How_Avatars_Influence_User_Behavior_A_Review_on_the_Proteus_Effect_in_Virtual_Environments_and_Video_Games/links/624997f421077329f2eec0f7/How-Avatars-Influence-User-Behavior-A-Review-on-the-Proteus-Effect-in-Virtual-Environments-and-Video-Games.pdf\" rel=\"noopener noreferrer\">Praetorius, &amp; G√∂rlich</a>, 2020). Employers are becoming more interested in the use of the metaverse for meetings (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://arpost.co/2022/11/11/expressvpn-survey-immersive-tech-workplace/\" rel=\"noopener noreferrer\">Jaehnig</a>, 2022). It is reasonable to predict that educators will be holding meetings that are now on-campus or in Zoom with their learners in the metaverse within five years. Due to the demand for these human-like behaviors, avatar creators and platforms are adding more movements like blinking, sitting, or gesturing.</p>\n<h3 class=\"article-editor-content__heading\">3.6 Generative Activity</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúAdd prompts to engage in generative activities such as summarizing, mapping, drawing, imagining, self-testing, self-explaining, teaching, and enacting.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: Interestingly, here the research reaches a nexus; several different sources point in the same direction. Mayer called these generative activities and points to their use <i>within the learning act</i>, as a guided form of practice, ‚ÄúInsert prompts to engage in generative learning activities within the instructional episode‚Äù and ‚Äúlearners must use the material from the lesson rather than simply remember it‚Äù (2020, p. 371). From this, an activity within XR would be ideal. However, generative activities are not exclusive to happening within XR. Wallace stated in <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://endurancelearning.com/blog/id-for-non-training-professionals/\" rel=\"noopener noreferrer\">Washburn</a> (2023) that all learning points to some place in the future where the results are played out‚Äìideally in a workplace or high stakes setting; it is the final performance that counts. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.youtube.com/live/l3tw6O8Hn-s?feature=share&amp;t=1663\" rel=\"noopener noreferrer\">Dede </a>(2021) pointed out the importance of onboarding and off-boarding as where the learning occurs primarily. Mayer conceded that <strong>generative activities likely need to be taught first as behaviors before asking a learner to perform them</strong> (2020). That is, learners need to be taught what summarizing is before being asked to summarize. This is a valid and somewhat overlooked point. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=PXRJEAAAQBAJ&amp;lpg=PP1&amp;ots=UpbIsA4SJU&amp;dq=learning%20experience%20design%20Clark&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">D. Clark</a> referred to these activities as ‚Äúeffortful learning‚Äù or ‚Äúdesirable difficulties‚Äù (2022, p. 3) and <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.worklearning.com/wp-content/uploads/2018/02/Thalheimer-The-Learning-Transfer-Evaluation-Model-Report-for-LTEM-v11.pdf\" rel=\"noopener noreferrer\">Thalheimer</a> (2006) supported retrieval practice, spaced practice, or interleaving approaches. Each of these researchers has a slightly different view into the same problem.</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\"><strong>They seem to point to the need for a certain amount of learner effort (not just clicking), with guidance, that should occur <i>within</i> XR and then a follow-on amount of learner effort <i>after</i> leaving XR.</strong></p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">What might this look like? Here, we reach the edges of known ID in the metaverse universe [Editor Heather here: fresh off the presses! This just hit ResearchGate last month: <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/publication/374151193_Collaborative_generative_learning_activities_in_immersive_virtual_reality_increase_learning\" rel=\"noopener noreferrer\">Collaborative generative learning activities in immersive virtual reality increase learning</a>], but <strong>we can take with us what we already know.</strong></p>\n<p class=\"article-editor-content__paragraph\">The key question to ask is: <strong>In real life</strong>, where do learners practice in place<strong><i> </i></strong>and later perform when the stakes really matter?¬† How something is done in real life should be the template that we use to start thinking of how the behavior should be prompted in the metaverse.</p>\n<p class=\"article-editor-content__paragraph\">Here is an example: Learners do science labs in real life. They practice doing a procedure under the watchful eye of an instructor. It is usually fine if they fail because they can start again but there is some risk and limitation of resources. In XR, the same lab can be set up as practice where learners can repeat interactions, control the speed, and engage in plausible manipulations of scientific equipment (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.idpublications.org/wp-content/uploads/2022/04/Full-Paper-THE-EFFECT-OF-VIRTUAL-LABORATORY-ON-STUDENT-TEACHERS%E2%80%99-ACHIEVEMENT-IN-INTEGRATED.pdf\" rel=\"noopener noreferrer\">Asare, Annan, &amp; Ngman-Wara</a>, 2022). The scripted practice available within XR should be added to other generative activities which could be inside and/or outside of XR such as learners self-explaining what is happening in the experiment during a video recording of the experience or learners teaching what would happen if the variables changed or if there was a chemical spill.</p>\n<h3 class=\"article-editor-content__heading\">3.7 Immersion</h3>\n<p class=\"article-editor-content__paragraph\">Summary: ‚ÄúDo not convert lessons into 3D immersive virtual reality.‚Äù</p>\n<p class=\"article-editor-content__paragraph\">ID: At this point, this article series would appear to come to a stop.</p>\n<p class=\"article-editor-content__paragraph\">This last principle basically states do not use 3D. This article series posits, do use 3D, if it is the right thing to do. Returning to the beginning assumptions:</p>\n<ol class=\"article-editor-content__ordered-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Learners experience the virtual as real.</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Learning outcomes are expected to be equal to other media.</p>\n</li>\n</ol>\n<p class=\"article-editor-content__paragraph\">It goes to follow, therefore, that if the designs will be accepted by the learners as real experiences and if the learning outcomes are the same as for other forms of media, the decision to go forward with the design should only occur <strong>if the lesson cannot reasonably be done in 2D and meets at least one of the conditions of saving time, money, or danger.</strong> Stepping outside of the learning objective decision, one could argue that 3D allows for added immersion and presence. But in that case, the ID should ask ‚ÄúIs immersion or presence<i> critical to the learning objective</i>?‚Äù</p>\n<p class=\"article-editor-content__paragraph\">Acknowledging the affordance of immersion, Mayer pointed out that the case for immersion is often wrapped into the learner's feelings of interest and motivation (2020, p.361). The logic goes that if a learner is motivated, they will learn more. Research shows that interest and motivation wane and learning performance drains away with it.</p>\n<p class=\"article-editor-content__paragraph\">The case for presence can be tied with a personal feeling of being there. The more a learner takes on the experience as real and really happening to them, the more the learning should stick with them. Contrarily, research shows that distraction due to extraneous processing seems to cancel any benefit that might be gained (Mayer, 2020). <strong>In sum, the research does not predict at this time that presence will increase learning.</strong></p>\n<p class=\"article-editor-content__paragraph\">Finally, this tidbit might tip the scales for a decision. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=v1uzCgAAQBAJ&amp;lpg=PR17&amp;ots=TNCJkGdMdm&amp;dq=clark%20mayer&amp;lr&amp;pg=PR17#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">Clark and Mayer</a> recommended this strategy from e-learning: ‚ÄúUse facilitative techniques that support social presence‚Äù (2016, p. 313). This tips the balance of synchronous versus asynchronous learning towards synchronous and shows an affordance <i>not before mentioned:</i> the benefit of social learning in XR.</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">Wise uses of XR seem to contain elements <i>of bringing learners together</i>.</p>\n</blockquote>\n<p class=\"article-editor-content__paragraph\">This should be leaned into in designs, if possible. Therefore, if learning designs can minimize extraneous processing and are best done in 3D, next we should ask what is different about <i>designing</i> for 3D.</p>\n<p class=\"article-editor-content__paragraph\">That will be Part 6. Stay tuned!</p>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/instructional-design-metaverse-part-1-heather-dodds-ph-d-/\" rel=\"noopener noreferrer\">Part 1</a> was the Introduction.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part-2.html\" rel=\"noopener noreferrer\">Part 2</a> covered Theory and Scope.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part.html\" rel=\"noopener noreferrer\">Part 3</a> was Myths versus Reality.</p>\n<p class=\"article-editor-content__paragraph\"><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse-part_8.html\" rel=\"noopener noreferrer\">Part 4</a> covered the Characteristics of Success.</p>\n<p class=\"article-editor-content__paragraph\">Want to see my full references? <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse.html\" rel=\"noopener noreferrer\">Have at it</a>.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhWJHyMDg5I_QKR9jwka682mXHi6PQ-tOE-4p3mmmPHeCD24lSkRhmS9WBmeB5fs2_tzYNd69qEIj9-oYt1eFp1a2XuRPiSsX-mxdEWYTFIEUIS4X_MZmloYkmaFhbHAj51abQxG2erb5X6wVV09YEZVzuHCZzArobRnryLclE46yfEl6vW8D-RXhDSH3M/w640-h358/heather_dodds_Blend_full_color_charcoal_and_game_cover_of_Legen_b594ba17-d6da-4575-9c4f-477ff847a586%20(1).png\" width=\"640\" height=\"358\" border=\"0\" data-original-height=\"816\" data-original-width=\"1456\" data-is-external-image=\"true\"><figcaption>Midjourney and Me. Prompt: Blend full color charcoal and game cover of Legends of Zelda, an attractive woman with short blonde hair and blue eyes wears hooded cloak, casting a glowing spell in a laboratory, cinematic lighting, fantasycore, blue and green color scheme</figcaption></figure>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p>Originally reposted on October 11, 2023.</p>\n<p class=\"article-editor-content__paragraph\"><span id=\"docs-internal-guid-d457ff87-7fff-a165-a3d4-9641d95e2994\" style=\"background-color: transparent; color: black; font-family: 'Times New Roman',serif; font-size: 11pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline;\">#InstructionalDesign #XR #Multimedia #Principles #Mayer #LXD #ID #L&amp;D #InstructionalDesigner #WebXR #3D #2D #ExtraneousProcessing #Coherence #Signaling #Redundancy #SpatialContiguity #TemporalContiguity #EssentialProcessing #Segmenting #PreTraining #Modality #GenerativeProcessing #Multimedia #Personalization #Voice #Image #Embodiment #GenerativeActivity #Immersion #Presence #EffortfulLearning #DesirableDifficulties #RetrievalPractice #SpacedPractice #Interleaving #LearnerCentric #edtech</span></p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/698/Part-51.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-11T14:55:00-04:00",
            "date_modified": "2025-08-02T15:06:23-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-4-characteristics-of-success.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-4-characteristics-of-success.html",
            "title": "Instructional Design in the Metaverse Part 4 Characteristics of Success",
            "summary": "Welcome to Part 4 of this series that proposes instructional design principles for the metaverse. Hopefully, you've read Parts 1, 2, and 3 because we need to remember this: Learning outcomes are expected to be equal to other media. So what are the characteristics that&hellip;",
            "content_html": "<div class=\"separator align-left\" style=\"clear: both; text-align: center;\"><span style=\"color: var(--text-primary-color); font-family: var(--editor-font-family); font-size: inherit; font-weight: var(--font-weight-normal);\">Welcome to Part 4 of this series that proposes instructional design principles for the metaverse. Hopefully, you've read Parts 1, 2, and 3 because we need to remember this:</span><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjHlZ2piQQlZtID3fFc_h0rXv-CL4zKZVT6evuJa4Svxu-ectTV59mTOmLlpb8O1U-QW_eqJRw2Oukw64L3bOnNqV7Ksj1ksJ5oLiUq55SSYnO56O59jsxp6QP8D2hBRXqfF-_FM6dJbdu75ZlSCBSY_0DTrHkt5Ko4fE0l2Fv4NRyfgGrCAvQKd2cMBjc/s2240/Part%204%20Characteristics%20of%20Success.png\" style=\"margin-left: 1em; margin-right: 1em;\"></a></div>\n<blockquote>Learning outcomes are expected to be equal to other media.</blockquote>\n<p class=\"article-editor-content__paragraph\">So what are the characteristics that predict success for an educational experience? Read on.</p>\n<h2 class=\"article-editor-content__heading\">Characteristics of Success</h2>\n<p class=\"article-editor-content__paragraph\">By the time IDs are often introduced to learning projects, the decision to incorporate XR technologies might already be made. Yet, IDs might be tasked with evaluating choices for <a href=\"https://docs.google.com/document/d/1FcHXvL2SmWqNwnLpmc-0Ti2N6tQotVseBYWSjL39P2w/edit#heading=h.nnsa5urx8jnn\" rel=\"nofollow noopener\" target=\"_blank\">off-the-shelf XR experiences</a> or do-it-yourself (DIY) projects. Both choices have possibilities and limits and this part will point out what characteristics predict that an XR solution should work for a given implementation.</p>\n<p class=\"article-editor-content__paragraph\">IDs should complete a thorough market analysis for off-the-shelf experiences. However, learning standards and ratings have not moved from early research to implementation (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Lana-Dreimane/publication/338676708_Virtual_Reality_Learning_Experience_Evaluation_Tool_for_Instructional_Designers_and_Educators/links/613f19b8e4419c5e6ec9d8eb/Virtual-Reality-Learning-Experience-Evaluation-Tool-for-Instructional-Designers-and-Educators.pdf\" rel=\"noopener noreferrer\">Dreimane</a>, 2020). Thus, the experiences vary in quality with some being quite poor.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjDCG3cbqrp-zzn2winwvdqhQr4P1fkEce8B124r1SCOSMeEzoZ4On83LNyERpvlTpu1u6tQfhRQMj4DqmDK5YEptKA-Q_tTQwcXk2NR0bDMybGKFBisZh7fLlYfSBw-F2qvzHk2nJ1JqqFwF8jYQjpZ7ypNpSUqkKvUrCVqmtI_7YEuZuunJptYbTwFYI/w320-h191/Immune%20U%20Side%20Quest.png\" alt=\"Screen capture inside an unnamed game on immunology.\" width=\"320\" height=\"191\" border=\"0\" data-original-height=\"917\" data-original-width=\"1535\" data-is-external-image=\"true\"><figcaption>Yeah, I'm looking at¬† you unnamed game on immunology.</figcaption></figure>\n<div>\n<p class=\"article-editor-content__paragraph\">On the other hand, <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/i-taught-one-earths-first-courses-oculus-quest-2-heather-dodds\" rel=\"noopener noreferrer\">XR experiences not tagged as educational can be successfully used for learning</a> with careful implementation.</p>\n<p class=\"article-editor-content__paragraph\">In a DIY project, IDs could be asked to learn 3D programming, such as Unity or Unreal. Artificial intelligence (AI) is beginning to be used for 3D development and this could assist IDs. If IDs do engage primarily in programming and building assets, there is a risk that they will take their eyes off the goal of representing the learner. An ID should be constantly asking the question,‚Äúwhat is the learner experiencing?‚Äù and making sure that all decisions align to the planned purpose.</p>\n<p class=\"article-editor-content__paragraph\">In general, the research up to this point indicates these three characteristics predict a successful XR educational experience:</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\"><strong>it saves or manipulates time</strong></p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\"><strong>it saves money</strong></p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\"><strong>it reduces danger </strong>(<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://sts.stanford.edu/publications/experience-demand-what-virtual-reality-how-it-works-and-what-it-can-do\" rel=\"noopener noreferrer\">Bailenson</a>, 2018; <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.1007/978-3-030-58948-6_4\" rel=\"noopener noreferrer\">Ziker, Truman, &amp; Dodds,</a> 2021).</p>\n</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">While having one of these characteristics is good for continuing development, having two or all three characteristics can lead to very successful full implementation. For example, an XR experience for wind turbine maintenance training would currently save time, money, and danger.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjvEIIxeJLZPGPqjXdHqNmvEzgbVh300zh-ML4n0DxejXMucbm3iFmVKs69476vCKFg1UPmcta24Ik72yKl6nzzU-UukVUGlQSK8Up7nduoAKn9S6OGMnuuJzLmc-UHfAE77rpAQbLQ7ufGxr-Hsd9gXw2QhaUIc_nFTZYEi1ErlUveynu1J0hSapqml0Q/w640-h402/windmill%20turbine%20maintenance%20in%20VR%20example.png\" alt=\"Capture from ISS VR experience.\" width=\"640\" height=\"402\" border=\"0\" data-original-height=\"687\" data-original-width=\"1096\" data-is-external-image=\"true\"><figcaption>Capture from inside Mission: ISS</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Have all three regularly and you tend to be <a href=\"https://youtu.be/0DvF5J6Evx4?si=SwBVGPrhkXZQABGg\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">NASA</a>.¬† <a href=\"https://youtu.be/0DvF5J6Evx4?si=SwBVGPrhkXZQABGg\">https://accessmars.withgoogle.com/</a></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh6_YjB8ikKhUpzLAQXcLI1rWaURj-vPIkF17Tudzdpsp4vZmBo7HgghsxfzCI5yKZno-BlaAyAphtqBJhXKq5FhsZIUFGs514KreRWO3vnEzNKC8IgrmrdaoaNOWwIOgasRlkYOOYzwGu2hcUa5Sb8T-BEYE_QQz-m9MKfpj2ke3COjHUXcJZZJJvOBGU/w640-h372/Access%20Mars%20NASA.png\" width=\"640\" height=\"372\" border=\"0\" data-original-height=\"788\" data-original-width=\"1358\" data-is-external-image=\"true\"><figcaption><a href=\"https://youtu.be/0DvF5J6Evx4?si=SwBVGPrhkXZQABGg\">https://accessmars.withgoogle.com/</a> <br>Sadly, now defunct.</figcaption></figure>\n<h2 class=\"article-editor-content__paragraph\" style=\"text-align: left;\"><strong>It Saves or Manipulates Time</strong></h2>\n<p class=\"article-editor-content__paragraph\">XR experiences can manipulate time for instruction. For instance, an experience could involve time travel, speeding up, slowing down, or pausing time.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjEq_nprM1rsAOpZca3h7CxrfEkxum03r_Xf-tGuLLRqaqFw71BGIwlNXDrhr14RQI8YQSy1mZ8djWGx-Ld_4DqOiwXv5UE3V4g0UZMLSWWSVOWMjNENqq389JGaHT6RDtTUh8UkZiqKWHgosUJj7r5xjOFpTeKjfpqBkNh5Ns9RgikKwbQwVytS6H6Q94/w640-h320/River%20City.png\" width=\"640\" height=\"320\" border=\"0\" data-original-height=\"350\" data-original-width=\"700\" data-is-external-image=\"true\"><figcaption>Credit: River City Project, Harvard, Chris Dede: <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://muve.gse.harvard.edu/screenshots\" rel=\"noopener noreferrer\">https://muve.gse.harvard.edu/screenshots</a></figcaption></figure>\n<div class=\"separator\" style=\"clear: both; text-align: center;\">¬†</div>\n<p class=\"article-editor-content__paragraph\">[Editor Heather interjects: the River City Multi User Virtual Environment (MUVE) is a great example of <strong>time manipulation</strong>. Learners had to determine the cause of 3 diseases in a city on a river. This built pedagogically went where learners often struggle: determining cause in a multi-variable (READ: real world, messy, wicked) system. The build could pause or speed up time--very helpful while waiting for bacteria to grow.</p>\n<p class=\"article-editor-content__paragraph\">With time paused in the middle of a process, visual cues can add positively to the instruction (<a href=\"https://books.google.com/books?id=v1uzCgAAQBAJ&amp;lpg=PR17&amp;ots=TNCJnLhOfi&amp;dq=Clark%2C%20R.%20C.%2C%20%26%20Mayer%2C%20R.%20E.%20(2016).%20E-learning%20and%20the%20science%20of%20instruction%3A%20Proven%20guidelines%20for%20consumers%20and%20designers%20of%20multimedia%20learning.%20&amp;lr&amp;pg=PR17#v=onepage&amp;q&amp;f=false\" rel=\"nofollow noopener\" target=\"_blank\">Clark &amp; Mayer</a>, 2016).</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg7oBc4GWfw5F_Na_ggXRCSovyv3TR5b238SsXumBHaxAp9QgYuTn6o98za0jR2aJtD3-bnkw01F5mGwVFuIzjJsrgWHRz_C75s_t-hQbeeZ6AKnY_epjmaGb4ub2sg2U30u8hfspmHolB6iQHJCXK2BlITqZbP1PaS7JCpsmWHkZ5o4UMX43omu-UaL9A/w640-h304/Navigation%20research.png\" width=\"640\" height=\"304\" border=\"0\" data-original-height=\"339\" data-original-width=\"715\" data-is-external-image=\"true\"><figcaption>Navigation research that showed that getting navigation instructions from an avatar was better than just arrows. <br>Note: VERY early research. <br>Source: <a class=\"article-editor-content__link article-editor-content__link\" data-original-attrs=\"{&quot;data-original-href&quot;:&quot;http://nectar.northampton.ac.uk/16606/1/Dohan_etal_ACM_2022_Deep_learning_based_recommenders_for_the_improved_user_navigation_in_VR.pdf&quot;}\" href=\"https://draft.blogger.com/#\" rel=\"noopener noreferrer\">http://nectar.northampton.ac.uk/16606/1/Dohan_etal_ACM_2022_Deep_learning_based_recommenders_for_the_improved_user_navigation_in_VR.pdf</a></figcaption></figure>\n<p class=\"article-editor-content__paragraph\">XR experiences can also reduce instructional time overall because the training can be delivered more efficiently to the learners. For example, workplace training that has been preloaded onto VR headsets can be shipped to remote workers, saving travel time.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhoTpBLZs8moVfWMv_232G-ftrAT2DfL6uDa4NaNmA7XpBg2wQtJhuvcxV4znaG9ygv0exH6dnS1yPdi_DT2k5QzYv2mFFa5qfI4g6UqzxUnIa0Og3EIvzKwxyeNbQCFA7q93fpc9QQXWv7zPQEzmt8tgahMdCf2x_8CnGj7bsOEwncnuj_tqpyik5G550/w640-h336/seasickness%20treated%20with%20vr.png\" width=\"640\" height=\"336\" border=\"0\" data-original-height=\"703\" data-original-width=\"1336\" data-is-external-image=\"true\"><figcaption>Treating sea sick ship captains <i>at sea</i> with VR. <br>Credit: <a class=\"article-editor-content__link article-editor-content__link\" data-original-attrs=\"{&quot;data-original-href&quot;:&quot;https://youtu.be/E6jFqqy0wes?si=Eazci6iPap16hLsw&quot;}\" href=\"https://draft.blogger.com/#\" rel=\"noopener noreferrer\">https://youtu.be/E6jFqqy0wes?si=Eazci6iPap16hLsw</a></figcaption></figure>\n<br>\n<p class=\"article-editor-content__paragraph\">IDs should be aware that with this characteristic, <strong><i>many 2D simulations can do the same</i></strong> time manipulation and savings<strong><i> for possibly lower costs</i></strong>.</p>\n<h2 class=\"article-editor-content__paragraph\" style=\"text-align: left;\"><strong>It Saves Money</strong></h2>\n<p class=\"article-editor-content__paragraph\">XR experiences can save money over other forms of learning. For example, it would cost a lot of money to take your learners to the Moon in real life. In XR, space travel is much cheaper.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh61GzuLeZd1EZi-VcsGR5PJ8RbFLeRZkZKshWjwI8AhO6dssjyflceln7JTjfGi5kYkL54AKTvujtyiUVe8ZyheFh4MulB-Q34_8IoxuozlGeHCpOwkS_rmqLcj6anMEuwwysY2aCWSivQUzCNyTJzE8ddCIWYyYpVc_z9o4wpLCAHtGG1OFyTZtcGHk4/w640-h340/Mission%20ISS.png\" width=\"640\" height=\"340\" border=\"0\" data-original-height=\"694\" data-original-width=\"1309\" data-is-external-image=\"true\"><figcaption>Capture from Mission: ISS. Space travel that is much cheaper than being an business oligarch.</figcaption></figure>\nThose unfamiliar with development trends might comment that the metaverse is not currently cheaper than other media. As of this writing, costs are dropping [Editor Heather reminds you that 1 of the 2 things<i> </i><a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/virtual-reality-soft-skillsmaybe-heather-dodds/\" rel=\"noopener noreferrer\"><i>I actually liked</i> about the PwC study was the calculation</a> that if you make a build for more than 3,000 users, it will be cheaper overall to do in XR versus e-learning] with the arrival of artificial-intelligence (AI) developed resources.¬†\n<p class=\"article-editor-content__paragraph\">Immersive web (WebXR) options allow approximately 20 learners to join one virtual space with a web browser, no additional equipment. Development prices do rise with more complexity.</p>\n<p class=\"article-editor-content__paragraph\">One final note: the ‚Äòtime is money‚Äô statement does hold true here. Often, an XR experience that saves time also saves money.¬†¬†</p>\n<h2 class=\"article-editor-content__paragraph\" style=\"text-align: left;\"><strong>It Reduces Danger</strong></h2>\n<p class=\"article-editor-content__paragraph\">This characteristic, the metaverse reduces danger, also includes impossible activities. While <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://aperturesciencellc.com/vr/VisualDesignMethodsforVR_MikeAlger.pdf\" rel=\"noopener noreferrer\">Alger </a>(2015) properly suggested that any content that was inherently 3D in the first place is ideal for XR development, XR is not limited to the real and actual. It can expand to the phantasmagorical and impossible. For instance, taking learners to look inside of an operating nuclear reactor would be dangerous in real life. This can be replicated in XR with no added danger for the learners.¬†</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhFfCSbWFJnh8Y9HZI_2jZ4xfKuyCRY9LIjUh7RemUQbTdL9z4v57gueKAN_FPuDGNOgycuW4l00r2CMQe1BqnvwTlv65dVAcGa5geQ7uwlfsfRl04Uh5qNKmV_HY_qKl407D4_MpgtZdBB6T_T0NIJ3cYvaNWj62Ulrjhgr8xfwyUjyIbT0pvGNTQm0Pk/w640-h360/VR%20Nuclear%20Reactor.png\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"540\" data-original-width=\"960\" data-is-external-image=\"true\"><figcaption>How a nuclear reactor generates electricity. Don't try this at home unless you are in VR.</figcaption></figure>\n<br>\n<p class=\"article-editor-content__paragraph\">IDs should remember that some environments in the metaverse can still represent psychological risk if not real danger. In the Proteus Effect, learners could change their behavior depending on what their avatar is experiencing (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Daniel-Goerlich/publication/347582766_How_Avatars_Influence_User_Behavior_A_Review_on_the_Proteus_Effect_in_Virtual_Environments_and_Video_Games/links/624997f421077329f2eec0f7/How-Avatars-Influence-User-Behavior-A-Review-on-the-Proteus-Effect-in-Virtual-Environments-and-Video-Games.pdf\" rel=\"noopener noreferrer\">Praetorius, &amp; G√∂rlich</a>, 2020). As a result, a learner‚Äôs avatar walking into fire might be a frightening experience even if it is physically safe. Examples of risks include claustrophobia, fear of heights, hostility, prejudices, and negative social pressures.</p>\n<p class=\"article-editor-content__paragraph\">In all cases, IDs should keep the learner primarily in mind. If it scares a learner <i>and it was not meant to</i>, it should be removed from the design.</p>\n<hr>\n<p class=\"article-editor-content__paragraph\">Let's take a short pause here-- we're about halfway through these articles and let's propose some questions.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Question:</strong> I know of some educational experiences that were VERY expensive to build, they cost a lot now, and they work great. Your formula would NOT necessarily predict their success.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Answer:</strong> The 'saving money' part is <strong>compared to the real world</strong>. So while I respect that some experiences are VERY expensive, I'm happy they work great. I just bet they are a LOT cheaper in XR than doing whatever it is in real life.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Q:</strong> <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://youtu.be/GOYrC1hH6Ak?si=6ez3Q6OAgkGLqybb\" rel=\"noopener noreferrer\">Jeremy Bailenson has his DICE formula</a>: <strong>D</strong>angerous,<strong> I</strong>mpossible, <strong>C</strong>ounterproductive, and <strong>E</strong>xpensive. Why should we remember your shorter \"time, money, danger\" version instead?</p>\n<p class=\"article-editor-content__paragraph\"><strong>A:</strong> With all respect to Jeremy, he has a lot of advantages at getting his message out (white, male, Stanford, and so on). But I developed my list -- as best as I can tell-- simultaneously to his (my 1st publication on it is 2013). So I'm claiming <strong>co-evolution</strong> because I believe we were looking at the same pile of research up to that time. What I don't like about his list (even though yes, he's got an acronym and I don't) is that his list is counterintuitive to understand. The 4 conditions he lists are <strong>what should be present in the real world <i>to then consider using VR</i></strong>. They are not 'when you should use VR'--- because if they were, how would \"counterproductive\" make sense? BTW, if you don't understand his use of counterproductive, watch the video I linked to his name above.</p>\n<p class=\"article-editor-content__paragraph\"><strong>Q:</strong> But you don't have Impossible on your list?</p>\n<p class=\"article-editor-content__paragraph\"><strong>A:</strong> I subsume the impossible inside the dangerous. Cause it is <i>really</i> dangerous to do the impossible. üòâ</p>\n<p class=\"article-editor-content__paragraph\"><strong>Q:</strong> OK, last question. What if an experience does not save time, does not save money, and isn't less dangerous (relatively) than the real thing?</p>\n<p class=\"article-editor-content__paragraph\"><strong>A:</strong> Besides realizing that Parts 1-3 basically advised against even thinking to make that experience, I say \"even a broken clock is right twice a day.\" There is always a chance, however low. These 3 guidelines are based on years of watching experiences rise and fall. Odd, surprising builds still happen and more luck to them.</p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">I've seen more success that I can chalk up to <strong>the people present </strong> <strong>than the tech present</strong>.</p>\n</blockquote>\n<hr class=\"article-editor-content__horizontal-rule\">\n<figure class=\"post__image\"><a data-original-attrs=\"{&quot;data-original-href&quot;:&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjV9MOt2jZwPOy5qNQDZOrUtkSEPAMeggiRhWgEvBM7BOrddgn2PdgwTVZo4hp3XKMWdJZfsHp2UhU799rEBoVPSmbCp4Rbts-uxRmyAhNaw1SJtnvtF3hwKsbmwCyu25DguBhK1bxIFUQFZnMY4hQbQlH2ACv7TM40LxxsAbtXJOX-cYethjF-Dl0zK8s/s2240/ID%20in%20the%20Meta%20Part%204.png&quot;,&quot;style&quot;:&quot;&quot;}\" href=\"https://draft.blogger.com/#\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjV9MOt2jZwPOy5qNQDZOrUtkSEPAMeggiRhWgEvBM7BOrddgn2PdgwTVZo4hp3XKMWdJZfsHp2UhU799rEBoVPSmbCp4Rbts-uxRmyAhNaw1SJtnvtF3hwKsbmwCyu25DguBhK1bxIFUQFZnMY4hQbQlH2ACv7TM40LxxsAbtXJOX-cYethjF-Dl0zK8s/w640-h360/ID%20in%20the%20Meta%20Part%204.png\" alt=\"Decorative image in the same theme as the banner image: an instructional designer travels through a Fantasia-like world.\" width=\"640\" height=\"360\" border=\"0\" data-original-height=\"1260\" data-original-width=\"2240\" data-is-external-image=\"true\"></figure></a></p>\n<p>Part 5 is where the real meat-and-potatoes begins for Instructional Designers. Hope you're hungry.</p>\n<p class=\"article-editor-content__paragraph\">Part 1 was the Introduction.</p>\n<p class=\"article-editor-content__paragraph\">Part 2 covered Theory and Scope.</p>\n<p class=\"article-editor-content__paragraph\">Part 3 was Myths versus Reality.</p>\n<p class=\"article-editor-content__paragraph\">Want to see my full references? <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://heatheredodds.blogspot.com/2023/10/instructional-design-in-metaverse.html\" rel=\"noopener noreferrer\">Have at it</a>.</p>\n<p>This was originally posted on October 8, 2023 and simultaneously posted to <a href=\"https://www.linkedin.com/pulse/instructional-design-metaverse-part-4-heather-dodds-ph-d-/\" target=\"_blank\" rel=\"noopener noreferrer\">LinkedIn articles.</a></p>\n<p>#InstructionalDesign #XR #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #Time #Money #Danger #DICE #LearningStandards #OffTheShelf #DIY #RiverCity #MUVE #Vertigo #SeaSickness #MissionISS #AccessMars #NASA #ProteusEffect</p>\n<br>\n<p class=\"article-editor-content__paragraph\">¬†</p>\n</div>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/699/Part-4-Characteristics-of-Success1.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-08T14:06:00-04:00",
            "date_modified": "2025-07-31T17:55:44-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-3-myths-versus-reality.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-3-myths-versus-reality.html",
            "title": "Instructional Design in the Metaverse Part 3 Myths versus Reality",
            "summary": "This conceptual series proposes instructional design principles for the metaverse. You've arrived at Part 3. TL;DR Ready? Let's do some myth busting. The metaverse in education is an emerging topic and a potentially lucrative field, possibly set to supplant learning management systems as the next&hellip;",
            "content_html": "<p class=\"article-editor-content__paragraph\">This conceptual series proposes instructional design principles for the metaverse. You've arrived at Part 3.</p>\n<p class=\"article-editor-content__paragraph\">TL;DR</p>\n<ul style=\"text-align: left;\">\n<li class=\"article-editor-content__paragraph\">XR causes more learning and faster - Myth</li>\n<li class=\"article-editor-content__paragraph\">XR is active learning - Myth</li>\n<li class=\"article-editor-content__paragraph\">More immersion is better than less - Myth</li>\n<li class=\"article-editor-content__paragraph\">XR causes greater retention - Jury is still out.</li>\n<li class=\"article-editor-content__paragraph\">XR increases empathy - Danger Will Robinson Danger</li>\n<li class=\"article-editor-content__paragraph\">Learners and instructors like it - True! But this means nothing to learning.</li>\n<li class=\"article-editor-content__paragraph\">XR can impact far transfer - Jury is still out.</li>\n<li class=\"article-editor-content__paragraph\">Positives get published - True, so negative or null results often do not.</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">Ready? Let's do some myth busting.</p>\n<h2 class=\"article-editor-content__heading\">Myths versus Reality</h2>\n<p class=\"article-editor-content__paragraph\">The metaverse in education is an emerging topic and a potentially lucrative field, possibly set to supplant learning management systems as the next industry-wide educational platform (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://arpost.co/2023/02/10/extended-reality-learning-potential/\" rel=\"noopener noreferrer\">Spilka</a>, 2023). Improvements in technology are fostering an ‚Äúanytime at anywhere‚Äù implementation of the metaverse (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://link.springer.com/article/10.1186/s40561-022-00205-x\" rel=\"noopener noreferrer\">Tlili, Huang, Shehata, et al.</a>, 2022, p. 4). As interest in the metaverse as educational media has increased, misleading claims or myths have already circulated. These myths are often shrouded under the title of research until the curious probe a little deeper. This part will examine claims such as the metaverse will cause learners to learn more and faster, it represents active learning and is therefore better, it is more immersive than ever, learners retain more, it increases empathy, and learners like it so therefore they learn better. This section will mention areas where the research is still unknown, publishing bias, and what to look for when IDs read educational research on the metaverse.</p>\n<h3 class=\"article-editor-content__heading\">1 More and Faster</h3>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi9UKDIAWxrLC8tlB5uJoiocMMZh97xdddcAQAgsmUdAC0ng6uuo2lHnx9bOQFrqJ4YUdYo3x5dmzzB4SJPDYKNHqYrcoNvrd_W46aemTsw1-IRDi9DxAgbDhsUrUbAMUWsgvGMK2SAiIsW4Q24ZMT03pWWNHB86CkqOPPKUk-O9swVNEPw0VMTrbZgpx4/s864/faster.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/faster.png\" alt=\"Screen capture of report showing that VR took one-quarter of the time that classroom did, hence the origin of the VR is 4x faster myth.\" width=\"640\" height=\"548\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/responsive/faster-2xl.png 1920w\"></a></div>\n<p>¬†</p>\n<figure class=\"article-editor-content__figure-image\"><figure class=\"article-editor-content__figure-image-caption\"><img loading=\"lazy\" <figcaption ></figure>Faster. You keep using that word. I don't think it means what you think it means.¬† <br>Note: this is also a woeful use of a time chart; three different times do not add up to a pie.</figcaption>\n</figure>\n<p class=\"article-editor-content__paragraph\">Learners in the metaverse will learn more and faster; this is the first claim examined. IDs should maintain a healthy skepticism of claims that a certain media causes dramatic learning improvements. Claims often do not communicate instructional methods as <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Leonel-Morgado/publication/368434277_Educational_Practices_and_Strategies_with_Immersive_Learning_Environments_Mapping_of_Reviews_for_using_the_Metaverse/links/63ffc7680cf1030a5661703e/Educational-Practices-and-Strategies-with-Immersive-Learning-Environments-Mapping-of-Reviews-for-using-the-Metaverse.pdf\" rel=\"noopener noreferrer\">Beck, Morgado, and O‚ÄôShea (2023</a>) pointed out. Instead, current publishing focuses on outcomes-based research or what <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Charles-Reigeluth/publication/371304955_How_Do_We_Solve_a_Problem_Like_Media_and_Methods_207/links/647e04b6b3dfd73b7767f1d2/How-Do-We-Solve-a-Problem-Like-Media-and-Methods-207.pdf\" rel=\"noopener noreferrer\">Reigeluth and Honebein</a> called research-to-prove results that are ‚Äútypically operationalized by comparing a new medium to a traditional one‚Äù (2023, p. 2). For instance, a lesson in XR could be compared to a lesson in a textbook. Similarly, the <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.17226/24783\" rel=\"noopener noreferrer\">National Academies of Science, Engineering, and Medicine</a> advised that possible external validity of some studies is low in that ‚Äúthere is considerable evidence that a single instructional technology can lead to different outcomes when used by different learners in different contexts‚Äù (2018, p. 194). These claims usually represent the pitting of two very different instructional methods and thus cognitive workloads against each other.</p>\n<p class=\"article-editor-content__paragraph\">Here is an example of this claim. In a study incorporating virtual reality (VR) headsets for soft skills training, Scott Likens of PricewaterhouseCoopers claimed, ‚ÄúWe found the realism and performance feedback in virtual reality simulations helped people learn faster and retain more information around soft skills,‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.shrm.org/hr-today/news/hr-magazine/spring2021/pages/virtual-reality-training-spreads-its-wings.aspx\" rel=\"noopener noreferrer\">Zielinski, 2021</a>, para. 9). However, <strong>the accompanying published report contradicted these claims.</strong> When comparing information retention in VR versus an e-learning course, the authors ‚Äúquickly discovered retention scores were inconclusive, as the delta between pre and post-assessments in each modality was <strong>not significant</strong>‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.pwc.com/us/en/services/consulting/technology/emerging-technology/assets/pwc-understanding-the-effectiveness-of-soft-skills-training-in-the-enterprise-a-study.pdf\" rel=\"noopener noreferrer\">Eckert &amp; Mower, 2020</a>, p. 44, emphasis added). Thus, the two different media showed no different learning outcomes.</p>\n<p class=\"article-editor-content__paragraph\">Another claim is that the isolation effect of a headset causes faster learning, perhaps arguing that less distraction equals more focus. In the same study, Likens stated, ‚ÄúA lot of courses that normally take an hour could be completed in 20 minutes through VR because people are so immersed in scenarios, there are fewer distractions and the learning is very concentrated‚Äù (Zielinski, 2021, para. 10). Referring to the same study, ‚ÄúVR was x4 faster than classroom and x1.5 faster than e-learning‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=PXRJEAAAQBAJ&amp;lpg=PP1&amp;ots=UpbIsA4SJU&amp;dq=learning%20experience%20design%20Clark&amp;lr&amp;pg=PP1#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">D. Clark, 2022</a>, p. 190). Claims that learning is completed faster attempt to represent XR as a more efficient learning method, i.e., less time to learn equals learning faster. When compared to classroom learning, it is already known that 1:1 personalized learning is faster. In this case, the classroom learning was allotted to two hours and the VR experience took 29 minutes. Given that 29 minutes is approximately one-quarter of two hours, the touted line was that XR was four times (4x) faster. <strong>In fact, the XR media did not cause the learning to be completed faster, it was the 1:1 nature of the learning experience. </strong></p>\n<p class=\"article-editor-content__paragraph\">[Editor Heather here: this is the same study I wrote about <i>extensively</i> <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/virtual-reality-soft-skillsmaybe-heather-dodds\" rel=\"noopener noreferrer\">here</a> and <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.linkedin.com/pulse/seeking-integrity-part-2-vr-soft-skills-heather-dodds-ph-d-\" rel=\"noopener noreferrer\">here</a> and my colleagues wrote about <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://3starlearningexperiences.wordpress.com/2020/07/07/truth-or-truthiness-analysing-a-vr-study-using-gorards-sieve/\" rel=\"noopener noreferrer\">here</a>, in case you want to read more.]</p>\n<p class=\"article-editor-content__paragraph\">Further, there is at least one study that refutes this focusing-causes-faster-learning claim. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.sciencedirect.com/science/article/pii/S0959475217303274\" rel=\"noopener noreferrer\">Makransky, Terkildsen, &amp; Mayer</a> have found that immersive metaverse environments can be sensory overload for learners and therefore decrease the learner‚Äôs focus (2019). On the whole, claims for increased speed can often be attributed to more efficient learning methods.</p>\n<p class=\"article-editor-content__paragraph\">Lauding the media that manipulated instructional methods hides the fact that the learner could achieve the same results in a different media, given comparable time and resources.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgV7uj48V7gPUGkuFj7K6bZBjfveosGof8ohc6d8oq-on11wae7FzYDSOnQoVRHRdS5W0J9yHi3diqMa-oVaMQ9KosWK2gFpKmM61LrqdQGMP6QFmMY1Uypp_UjfQyWmw4_9w1YIdZC0aSdp35kXxK7-kNtPyVfyv2h7KpQa8O8Xk9DAXNFai43Ulo9BV0/w640-h208/Four%20hundred%20percent%20stick%20more.png\" alt=\"Screen capture of comment where OP claims to &quot;have seen stats that proclaim VR learning is up to 400% more effective than other forms of learning.&quot; Also, OP believes that VR learning sticks more.\" width=\"640\" height=\"208\" border=\"0\" data-original-height=\"168\" data-original-width=\"517\"></figure> data-is-external-image=\"true\">\n<figcaption >This is a 4x claim variant, with \"recall up to 400%.\" They throw in the 'control the distractions' claim too. <br>Upon request, the OP refused to provide a source.</figcaption>\n</figure>\n<p>[Editor Heather popping back in here about 5 months after this blog was originally published on 10/4/2023. I like to add examples \"from the wild\" when I see these claims and whaddaya know-- a claim popped up yesterday! Here you go! Feast your eyes on the 4x claim below along with the lack of reference/evidence/substantiation]</p>\n<p><a data-original-attrs=\"{&quot;data-original-href&quot;:&quot;https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjc8ywZWhh75THcDISdwnZ_-_-_2uwURV1mlKv70RCtdDMy9j-yKrTPirloJjc70Zx4Tekufs2Yzj8IVXvv4OQwsBFuMR3DGUxZoZEMpYzcobbm08MtOFfQlVKPvwF4vT_fwm-P7tVv1XaKFhxnNWj7HZZ1JU94AigDXSAratcS5dPF3qXoKbDo2JorHus/s837/4x%20claim%20highlighted.png&quot;,&quot;style&quot;:&quot;&quot;}\" href=\"https://draft.blogger.com/#\"><img loading=\"lazy\" src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjc8ywZWhh75THcDISdwnZ_-_-_2uwURV1mlKv70RCtdDMy9j-yKrTPirloJjc70Zx4Tekufs2Yzj8IVXvv4OQwsBFuMR3DGUxZoZEMpYzcobbm08MtOFfQlVKPvwF4vT_fwm-P7tVv1XaKFhxnNWj7HZZ1JU94AigDXSAratcS5dPF3qXoKbDo2JorHus/w506-h640/4x%20claim%20highlighted.png\" width=\"506\" height=\"640\" border=\"0\" data-original-height=\"837\" data-original-width=\"662\" data-is-external-image=\"true\"></a></p>\n<p>This particular example of the 4x is buried with a pro-Microsoft Teams article that I actually agree with (and posted another blog about <a href=\"https://heatheredodds.blogspot.com/2023/12/youll-be-using-xr-in-2024-and-you-will.html\" target=\"_blank\" rel=\"noopener noreferrer\">here</a><span data-keep-original-tag=\"false\"><span id=\"c2\" class=\"w4txWc oJeWuf\" data-keep-original-tag=\"false\" data-original-attrs=\"{&quot;role&quot;:&quot;region&quot;}\"><span class=\"MUhG4e OGjyyf\" data-keep-original-tag=\"false\" data-original-attrs=\"{&quot;data-blogurl&quot;:&quot;https://heatheredodds.blogspot.com/&quot;}\">)<br><br>I'm curious that the 4x was applied to \"retention rate\" and \"attention span\" and was compared (excuse me, conpared! üôÑ) to Teams or Zoom, which, to the best of my knowledge WAS NOT in the 4x PwC study. <br><br>I feel some, ahem, elaboration has occurred here.¬† And I find it interesting that while propping UP Teams (because it is rolling out immersive team meeting environments) this paragraph highlighted actually disses Teams.¬† I'm thinking this person is so excited and into rolling out stats that he's confused stuff.</span></span></span></p>\n<h3 class=\"article-editor-content__heading\">¬†Active Learning</h3>\n<figure ><figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi7Vgm5K87_V5ndBQevbgNn9LWJFP_n53ag49TBinc73nFulAFXm1ypEc0OGkbAyIPq2MvJz_vCAFKqOH6FxTCk0QteefYzxhAfd68MCSCrQ-1k33bDcvokYbAexTJKFoBIstrGUOQmfj0wGB9OXJDCE9I4m2_uEp1nTx1Hfx2IgDVP8Kcze11GKJ72Wyw/w640-h88/active%20learning.png\" alt=\"Screen capture of a comment claiming that being in a headset is the same as active learning.\" width=\"640\" height=\"88\" border=\"0\" data-original-height=\"102\" data-original-width=\"735\" data-is-external-image=\"true\"><figcaption>Claim: Being in a headset equals active learning.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Some claims state that learner-instigated avatar movement, in the form of moving hands, heads, or bodies, or the first-person point of view makes XR learning inherently active as opposed to passive. Intentional avatar movement is associated with manipulating content, which is the term embodiment or embodied learning (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.3389/frobt.2018.00081\" rel=\"noopener noreferrer\">Johnson-Glenberg</a>, 2018; <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.3389/fpsyg.2018.02364\" rel=\"noopener noreferrer\">Markowitz, Laha, Perone, et al.</a>, 2018). The claim begins with the given that active learning is known to be better than passive learning. Because XR is body-movement active, it must be active learning and thus cause more learning¬† (Johnson-Glenberg, 2018). However, research has shown that while embodiment does have a connection to learning, it does not exclusively <strong><i>cause</i></strong> learning. Truly, ‚Äúplatform is not destiny‚Äù as <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.researchgate.net/profile/Elena-Kalina-2/publication/352059688_Platform_is_not_destiny_Embodied_learning_effects_comparing_2D_desktop_to_3D_virtual_reality_STEM_experiences/links/60fb097e169a1a0103b1e03b/Platform-is-not-destiny-Embodied-learning-effects-comparing-2D-desktop-to-3D-virtual-reality-STEM-experiences.pdf?_sg%5B0%5D=started_experiment_milestone&amp;_sg%5B1%5D=started_experiment_milestone&amp;origin=journalDetail\" rel=\"noopener noreferrer\">Johnson‚ÄêGlenberg, Bartolomea, &amp; Kalina</a> stated in 2021 (p. 20). <strong>Just putting a learning experience with movement into XR does not make it active learning.</strong></p>\n<h3 class=\"article-editor-content__heading\">3 More Immersion</h3>\n<p class=\"article-editor-content__paragraph\">There are some claims that take issue with the second assumption stated earlier in this series: Learning outcomes are expected to be equal to other media (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\" rel=\"noopener noreferrer\">Mayer</a>, 2020). These claims state that earlier comparative media studies did not show improved results because the technology then was older. Thus, technology now utilizes a better <i>quality</i> of immersion. This claim reflects a modernist philosophical approach: newer is better. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://stanfordvr.com/mm/2015/cummings-mp-how-immersive.pdf\" rel=\"noopener noreferrer\">Cummings and Bailenson</a> (2016) reported that head tracking, stereoscopic visuals, and wider fields of view created more immersion than other visual or audio improvements. Yet Mayer wrote in 2020, ‚Äúthese comparisons between low-immersion and high-immersion media <strong>do not provide strong evidence </strong>for the instructional value of converting a 2D lesson rendered on a computer screen into a 3D lesson displayed with a head-mounted display in immersive virtual reality‚Äù (p. 365). Moreover, <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://ascelibrary.org/doi/abs/10.1061/%28ASCE%29ME.1943-5479.0001101\" rel=\"noopener noreferrer\">Abbas, Seoo, Ahn et al</a>. (2023) found that high levels of presence did not impact user behaviors. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.frontiersin.org/articles/10.3389/frvir.2022.742509/full\" rel=\"noopener noreferrer\">Ochs and Sonderegger</a> (2022) reported that learners that felt an increased sense of presence in VR scored worse on measures of memorization even when the learner simultaneously self-reported that they expected to do better in VR versus 2D. Finally, Makransky, Terkildsen, &amp; Mayer found that VR causes more presence but less learning (2019).</p>\n<p class=\"article-editor-content__paragraph\">Overall, these claims also fail to acknowledge that the main subject in media studies are humans (not the media), and we already know a great deal about how humans learn in 3D environments. These spaces exist outside of technology and are called classrooms. <strong>These claims that newer XR will cause more learning look more like calls to buy the latest technology. </strong></p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\"><strong>That is not instructional design research, it is marketing.</strong></p>\n</blockquote>\n<h3 class=\"article-editor-content__heading\">4 Greater Retention</h3>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgeVIw4VyaeF_v2Qt3DtcXjB31m0yIv3KMLfmVwFH-QLtHMvrf6FQGo34L2toNRxFYBap_Mkxiyf7DfSvGVY_wB8pADOv6Pf1YTJsVIb7HaxzuUmeYdz-OMTZmLwZMAZzeU0UTCZ-tP1qTL0SbLF6lxnwVbuiDxi5von8E_sibaVh-r5hyphenhyphen5hWuTwTsMUWE/w640-h478/better%20retention.png\" alt=\"Capture of post with text: It has been proven that people learn better through an immersive experience and &quot;retain material better&quot;.\" width=\"640\" height=\"478\" border=\"0\" data-original-height=\"784\" data-original-width=\"1050\" data-is-external-image=\"true\"><figcaption>Claim: better retention, \"it has been proven\". <br>Not so much.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">This claim states that XR enhances knowledge retention (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://iprjb.org/journals/index.php/IJHR/article/view/2018\" rel=\"noopener noreferrer\">Victor</a>, 2023). Studies of retention are still ongoing and difficult to find. Indeed, broad reviews such as those conducted by <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://link.springer.com/article/10.1007/s40692-020-00169-2\" rel=\"noopener noreferrer\">Hamilton, McKechnie, Edgerton, and Wilson</a> (2021) commented that finding ‚Äúlearning outcomes, intervention characteristics, and assessment measures associated with immersive virtual reality use has been sparse‚Äù (2021, p. 1). This aligns with Beck, Morgado, and O‚ÄôShea who contended that, ‚ÄúVery few literature reviews focus on the educational practices and strategies used in immersive learning environments. Thus, the problem is that we are evaluating outcomes without a comparable way to describe the educational approaches that led to those outcomes‚Äù (2023, p. 2). Therefore, retention could be achieved with XR implementation, but without more research detail, greater results might be attributable to the method, not the media.</p>\n<p class=\"article-editor-content__paragraph\">The use of the metaverse in education is not yet common. It is difficult to find studies that measure retention within learners <i>more than</i> 10 to 21 days after instruction. Practical workplace implementation would require much longer retention times. Therefore, <strong>this claim has not yet been supported or refuted</strong>.</p>\n<h3 class=\"article-editor-content__heading\">5 Increase Empathy</h3>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhTiuHUYgPmwx1DRrK2BKH3_FIHYgdJ-sl2sFPhZyqJB8ZjMGLqtgowxJeGCUGcZHLj5mWTY5D2l5Pr_eapfXBUDuffKJXG0PindHmiMZxyVgzV514Br0Asjh2Bq7VYv8ti2fo7KXlxnX7GhbYDC1LpazQbirKS3qE-Rv0Bb2N5CGJoTXiTfSz-aHvwS78/w640-h396/empathy%20machine.png\" alt=\"Capture of headline: Is VR the ultimate empathy machine?\" width=\"640\" height=\"396\" border=\"0\" data-original-height=\"449\" data-original-width=\"726\" data-is-external-image=\"true\"><figcaption>Someone seems to think so.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">Research on empathy indicates that this is an area of risk. Because of a first-person point of view in many XR experiences, learners perceive a direct impact of the experience which is meant to foster empathy. However, empathy, like presence, is nuanced. Indeed, in some empathy research, learners did not react with a positive and caring response, but instead with disgust and rejection (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://sts.stanford.edu/publications/experience-demand-what-virtual-reality-how-it-works-and-what-it-can-do\" rel=\"noopener noreferrer\">Bailenson</a>, 2018). Thus, the objective of the experience might be not only missed but soured.</p>\n<p class=\"article-editor-content__paragraph\">Clark, when writing about accessible pedagogy in immersive learning, advised to avoid first-person depictions of marginalized groups because XR experiences cannot portray the depth and spectrum of a person‚Äôs life. ‚ÄúInstead of teaching students what it‚Äôs like to be blind, consider having them deconstruct the ways vision is assumed in how spaces are designed, as well as the ways their understandings of vision impact how they interact with others,‚Äù then ‚Äúfocus on bringing awareness to the assumptions built into the physical world around them‚Äù (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://dlfteach.pubpub.org/pub/vol2-clark-recommendations-for-accessible-pedagogy-with-immersive-technology\" rel=\"noopener noreferrer\">J. Clark</a>, 2021, Recommended Administrative Considerations section, para. 4). Therefore, <strong>XR to foster empathy should be approached with extreme caution.</strong></p>\n<h3 class=\"article-editor-content__heading\">6 Learners and Instructors Like It</h3>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgJfJP35szeqRXlKz4uKMYCHo6GVq5XPBRPWTZXRJ8tg2ffHodv3UQhyphenhyphenpEKy8odkezTZFGNsIoL9jSWPxZvGQZK2zYeQyZELqpaZUa2zeeMJvLFUwKcfAEeVHbqS_OdPVnjmyKicOsH8LnQefGG9hjgVLLw3vr8QQ6IjikR2WQjmfAQPKexZf0IuaVmTak/w640-h378/pwc%20edit%20on%20numbers.png\" alt=\"Capture of impressively high &quot;more confident&quot; and &quot;more emotionally connected&quot; numbers from VR learning.\" width=\"640\" height=\"378\" border=\"0\" data-original-height=\"409\" data-original-width=\"693\" data-is-external-image=\"true\"><figcaption>Forward-looking statements of optimistic activity. <br>Unfortunately NOT strongly connected to learning.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">This learning claim, that learners liking a learning experience will then learn more, is perhaps the most common. To the contrary, there is no research-based connection between liking an experience and learning success (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://psycnet.apa.org/manuscript/2016-29687-001.pdf\" rel=\"noopener noreferrer\">Hughes, Gregory, Joseph, et al</a>., 2016; <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.unlv.edu/sites/default/files/page_files/27/Engineering-MetaAnalysis-BobUttl.pdf\" rel=\"noopener noreferrer\">Uttl, White, &amp; Gonzalez</a>, 2017) . <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.worklearning.com/wp-content/uploads/2018/02/Thalheimer-The-Learning-Transfer-Evaluation-Model-Report-for-LTEM-v11.pdf\" rel=\"noopener noreferrer\">Thalheimer</a> further discounted the connection between learners liking their learning and achieving their learning, when he stated that ‚Äúmeasuring interest is an inadequate way of measuring learning‚Äù (2018, p. 26). Therefore, while it is pleasant for learners to enjoy an experience, it has no firm connection to a learning outcome. Beyond the learner, education professionals should use caution when thinking that emotional motivation will work <strong>over the long term</strong>. Instructors often become enthralled with possibilities of XR and start to believe that the feeling of being there (a combination of presence, embodiment, and immersion) will make a positive difference. <strong>Research and theory are not forecasting this.</strong> However, the flame of excitement among professionals should not be extinguished. <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://books.google.com/books?id=v1uzCgAAQBAJ&amp;lpg=PR17&amp;ots=TNCJkGdMdm&amp;dq=clark%20mayer&amp;lr&amp;pg=PR17#v=onepage&amp;q&amp;f=false\" rel=\"noopener noreferrer\">Clark and Mayer</a> advocated for a <i>tempered</i> approach where the ID can keep to the best learning practices and not be distracted by the media:</p>\n<p class=\"article-editor-content__paragraph\">‚ÄúThe challenge in e‚Äêlearning, as in any learning program, is to build lessons in ways that are compatible with human learning processes. To be effective, instructional strategies must support these processes. That is, they must foster the psychological events necessary for learning. While the computer technology for delivery of e‚Äêlearning is upgraded regularly, <strong>the human side of the equation‚Äîthe neurological infrastructure underlying the learning process‚Äîis very old</strong> and designed for change only over evolutionary time spans. In fact, technology can easily deliver more sensory data than the human nervous system can process. <strong>To the extent that attention‚Äêgrabbing audio and visual elements in a lesson interfere with human cognition, learning will be depressed</strong>‚Äù (2016, p. 24, emphasis added).</p>\n<h3 class=\"article-editor-content__heading\">7 Near Versus Far Transfer</h3>\n<p class=\"article-editor-content__paragraph\">Claims about near transfer outcomes will be addressed just ahead [look for Whitney]. Results showing positive far transfer from XR applications, however, are elusive in a similar way to the retention results. Research shows equivalent or mixed performance to traditional media (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.bendsawyer.com/wp-content/uploads/2020/03/Kaplan-et-al-2020-VR-AR-and-MR-as-Training-Metaanalysis.pdf\" rel=\"noopener noreferrer\">Kaplan, Cruit, Endsley, et al</a>., 2021; <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://onlinelibrary.wiley.com/doi/abs/10.1111/jcal.12375\" rel=\"noopener noreferrer\">Makransky, Borre‚ÄêGude, &amp; Mayer</a>, 2019) or worse performance (Makransky, Terkildsen, &amp; Mayer, 2019; <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://psycnet.apa.org/manuscript/2018-03101-001.pdf\" rel=\"noopener noreferrer\">Parong &amp; Mayer</a>, 2018). In particular, Mayer offered the Immersion Principle in 2020 which stated: ‚ÄúPeople do not necessarily learn better in 3D immersive virtual reality than with a corresponding 2D desktop presentation‚Äù (p. 357).</p>\n<p class=\"article-editor-content__paragraph\">Intuitively, because XR can replicate real world environments where the learning <i>would be applied</i>, far transfer seems like a reachable goal. (Tlili, Huang, Shehata, et al., 2022) wrote that the technology can enhance and allow for transfer. Johnson-Glenberg noted that despite requests for more research into XR, ‚Äúresources and affordable technologies were not readily available‚Äù (2018, p. 7) for educational research and that ‚Äúlongitudinal effects of VR exposure are unknown at this point‚Äù (2018, p. 11). <strong>It is possible that not enough time has passed for the research community to measure the ‚Äòfar‚Äô in far transfer.</strong> In general, the ability to do worked practice exercises repeatedly in simulated real-world contexts suggests that XR should be <strong>at least equivalent</strong> when compared to other media for far transfer.¬†</p>\n<h3 class=\"article-editor-content__heading\">8 Positives Get Published</h3>\n<p class=\"article-editor-content__paragraph\">Research with positive results is published more often than research with negative or no results. This is not unique to metaverse applications. This is known as <strong>publication bias</strong> or the file drawer problem (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.1007/s10972-016-9475-2\" rel=\"noopener noreferrer\">Lederman &amp; Lederman</a>, 2016). It limits the results of a meta-analysis because if a particular form of learning is not effective, it usually is not published (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://link.springer.com/article/10.1007/s11191-019-00051-3\" rel=\"noopener noreferrer\">Cofr√©, N√∫√±ez., Santib√°√±ez et al.</a>, 2019). Thus, <strong>the published collection showing positive results with XR dominates over the no significant difference results.</strong></p>\n<p class=\"article-editor-content__paragraph\">As an added caveat, IDs should closely examine research funding <i>sources</i> and <i>sponsors.</i></p>\n<h2 class=\"article-editor-content__heading\">How Will I Know?</h2>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiTGCYNJCo-ElV90jmTLSlXR749fURmvs4oTaXDDQtU5-gNSHK3UxsWOdWX1y4zijMATv3GbgXzB8UhA5_wKwNYDD1Sv0eqr4STH7JWzRxhAAk9Lqmb7PpYDZBBVd6jDagdidaCEgGjsnweL8GtFGmjqNQW2yXJeWW9Huo9X2dJ7wutUWbBV0rucnzsN7I/w640-h640/How%20will%20I%20know%20Whitney%20Houston.jpeg\" alt=\"Single cover of How Will I Know? By Whitney Houston.\" width=\"640\" height=\"640\" border=\"0\" data-original-height=\"490\" data-original-width=\"490\" data-is-external-image=\"true\"><figcaption>You are welcome for that earworm. Who doesn't love Whitney, helping out with instructional design?</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">IDs are cautioned to examine metaverse research studies for these two major characteristics:</p>\n<ol class=\"article-editor-content__ordered-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\"><strong>Novelty effect.</strong> The novelty effect is when learners are exposed to a new media and they engage in increased effort and attention. It tends to positively impact learning outcomes (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.igi-global.com/chapter/transitions-in-student-motivation-during-a-muve-based-ecosystem-science-curriculum/230841\" rel=\"noopener noreferrer\">Metcalf, Chen, Kamarainen, et al</a>., 2019) but not always (Huang, Roscoe, Johnson‚ÄêGlenberg, et al., 2021). Further, \"studies of virtual reality-based learning are based on only short-term implementations, and although they might show statistically significant learning outcomes, the novelty effect is an important caveat to the research because many of these studies do not account for the decay of outcomes over longer periods of time.\" (Metcalf, Chen, Kamarainen et al., 2019, p. 97)</p>\n</li>\n</ol>\n<p class=\"article-editor-content__paragraph\"><strong>If a research study implements a one-time 20-minute XR intervention and claims to show learning improvement, the learners are likely experiencing the novelty effect.</strong></p>\n<ol class=\"article-editor-content__ordered-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\"><strong>Non-cognitively comparable methods.</strong> Studies where the learner is not put into the same cognitive workload with two different media should be viewed with skepticism over claims of better results (Reigeluth &amp; Honebein, 2023). For example, if a study stated that learners performed better in XR than paper-and-pencil-based learning, the results should be discounted due to the varying cognitive impact that the different media had on the learner (Parong &amp; Mayer, 2021). In one example, the experimental learner group was exposed to VR training after the standard training and then scored higher than the control group (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1422600/\" rel=\"noopener noreferrer\">Seymour, Gallagher, Roman, et al.</a>, 2002). The total training time increased. <i>This could have caused higher scores.</i> The two conditions, therefore, were not comparable. Furthermore, <a class=\"article-editor-content__link article-editor-content__link\" href=\"https://doi.org/10.17226/24783\" rel=\"noopener noreferrer\">the National Academies of Sciences, Engineering, and Medicine</a> noted that the prevalence of WEIRD populations (Western, educated, industrialized, rich, and democratic) used in educational research inherently exclude diverse learner populations and this makes it difficult to draw solid conclusions for all humans in all learning situations (2018). Thus <strong>what works for one group of learners might not work, nor even be comparable, for another group.</strong></p>\n</li>\n</ol>\n<p class=\"article-editor-content__paragraph\">Clark and Mayer summarized how to examine research claims for e-learning, but these questions equally apply to XR research.</p>\n<ul class=\"article-editor-content__bullet-list\">\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">‚ÄúAre the methods, content, learners, and context like yours?</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Does the experimental group outscore the control at a significance level of p &lt; .05? [Editor Heather here: How many of y'all KNOW what the phrase \"statistically significant\" means? I thought so. I'll write a future article on it so that you stop banging the \"XR will make a significant difference in education\" phrase around. I <i>hate</i> that. Be warned.]</p>\n</li>\n<li class=\"article-editor-content__list-item\">\n<p class=\"article-editor-content__paragraph\">Does the effect size favor the experimental group at a 0.5 level or higher (2016, p. 63)?\"</p>\n</li>\n</ul>\n<p class=\"article-editor-content__paragraph\">IDs will likely encounter innovators and early adopters who have anecdotal stories of how XR improved learning.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhtSgxQwsEfVCltgTTovuOX30rSD8KZFcpnhYMLsql5vuvjMeNk4cbId1jbrzxv3aZAJUIK_tLdCyv2z2PEpauTCiotMmqNPvnjd5gcOSqNjwzIQy2NDG6oef0oBjMC8Am9GZR7VRR51v1JEm-opxji2hhRgiTobOW7DAuLd6OMzftMZysDY9Y2zX1Pn-Q/w640-h316/passionate%20educator%20March%202020.png\" alt=\"Screen capture of comment from VR conference: I work with students weekly. They bring me &quot;bad&quot; kids from a last effort school where the kids will be expelled if they cause trouble again. Some of which are older kids who struggle to read and write. &quot;VR does NOT create better learning outcomes itself&quot; is a very suspect sentence. I can tell you 100% that VR is creating better learning outcomes for these students. The key is engagement. These students engage in VR even though they won't engage in a school setting. I promise you they are learning and developing skills.\" width=\"640\" height=\"316\" border=\"0\" data-original-height=\"210\" data-original-width=\"425\" data-is-external-image=\"true\"><figcaption>A passionate-for-VR educator describing what is likely the novelty effect with their students.</figcaption></figure>\n<p class=\"article-editor-content__paragraph\">These stories should be accepted with grace, as <strong>every form of media has the possibility to hit the perfect instructional moment with the right learning at the right time for the right learners.</strong></p>\n<p class=\"article-editor-content__paragraph\"><strong>¬†</strong></p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><strong><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhsViHcKAh9mob_ePnZMMBMXBz-i6WA5JJO0xbzz4BqIxrhiNkFKQNq41WzcziZhPqiq7TPEHmDckTThge7jpfI_IaZBrrTUc4WpdXjl7AYFnk9X369ziVwbBdM4ZZJqs3tZWmqHw0OsJHvx6xTfsssN_jkLrtl6y_EiBZrS0MALl4iQjBWF9osNWDS33c/s454/perfection.gif\" style=\"margin-left: 1em; margin-right: 1em;\">\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/perfection.gif\" alt=\"Animated gif of sprinkling, meaning chef's kiss, perfect.\" width=\"319\" height=\"320\" border=\"0\"><figcaption>I sprinkle just the right instructional media and methods here and PERFECTION.</figcaption></figure>\n</a></strong></div>\n<p class=\"article-editor-content__paragraph\">Longer term and wider implementation decisions, however, should be made more systematically, by thinking and rethinking the design decisions over time. IDs rarely have control over the large financial decisions that XR development requires, so their role can be one of consultant: offering all the options and pros and cons of each to the decision makers (<a class=\"article-editor-content__link article-editor-content__link\" href=\"https://edtechbooks.org/id_highered/immersive_learning_e\" rel=\"noopener noreferrer\">Dodds</a>, 2021). After reviewing research, IDs <strong>are ethically bound to point out if a learning objective can be met with a cheaper, more environmentally responsible, or more socially just media. </strong></p>\n<blockquote class=\"article-editor-content__blockquote\">\n<p class=\"article-editor-content__paragraph\">In summary, ‚ÄúAs a consumer of experimental research, you need to be picky!‚Äô (Clark &amp; Mayer, 2016, p. 56)</p>\n</blockquote>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p class=\"article-editor-content__paragraph\">Part 4 will answer \"How do I know I'm on the right trail with this [assigned] XR project?\" (Yeah, more Whitney!)</p>\n<p class=\"article-editor-content__paragraph\">Part 1 Introduction</p>\n<p>Part 2 Theory and scope</p>\n<p class=\"article-editor-content__paragraph\">My references</p>\n<hr class=\"article-editor-content__horizontal-rule\">\n<p class=\"article-editor-content__paragraph\">#InstructionalDesign #XR #Myth #LearningMyths #XRMyths #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #VRCausesFasterLearning #VRCausesMoreRetention #WEIRD #ActiveLearning #Immersion #Empathy #NearTransfer #FarTransfer #PositivesGetPublished #AcademicPublishing #NoveltyEffect #NonCognitivelyComparableMethods #HowToReadResearch #Anecdotes #Ethics #ExperimentalResearch</p>\n<p>This blog post was originally posted on October 4, 2023 and is simultaneously posted to a <a href=\"https://www.linkedin.com/pulse/instructional-design-metaverse-part-3-heather-dodds-ph-d-.\" target=\"_blank\" rel=\"noopener noreferrer\">LinkedIn article. </a>Some slight editing occurred upon repost.</p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/700/Seeking-integrity1.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-04T13:08:00-04:00",
            "date_modified": "2025-07-31T17:33:36-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-2-theory-and-scope.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-2-theory-and-scope.html",
            "title": "Instructional Design in the Metaverse Part 2 Theory and Scope",
            "summary": "This conceptual series proposes instructional design principles for the metaverse. You've arrived at Part 2 where I cover theory, application, and scope. If you are a theory nerd like me, you'll love this part. If not, hang on to your butts. Metaverse educational experiences, as&hellip;",
            "content_html": "<p id=\"ember1246\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">This conceptual series proposes instructional design principles for the metaverse. You've arrived at Part 2 where I cover theory, application, and scope. </span></p>\n<p id=\"ember1247\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> If you are a theory nerd like me, you'll love this part. If not, hang on to your butts.¬†</span></p>\n<h2 class=\"ember-view\"><span style=\"font-family: helvetica;\"> Theory and application</span></h2>\n<p id=\"ember1249\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Metaverse educational experiences, as replications of known reality, <i>can draw from every major learning theory already in existence</i> because metaverse experiences are often <strong>copies</strong> of the real world. <a href=\"https://doi.org/10.1007/7854_2022_404\">Checa and Bustillo</a> asserted that constructivism, behaviorism, cognitivism, and connectivism can be foundations for a wide variety of XR pedagogical approaches (2023). However, the specific affordances of presence and embodiment in the metaverse indicate that existing approaches that include simulations and experiential learning are applicable (Checa &amp; Bustillo, 2023; <a href=\"https://www.frontiersin.org/articles/10.3389/frobt.2018.00081/full?source=post_page---------------------------\">Johnson-Glenberg, 2018</a>; <a href=\"https://books.google.com/books?hl=en&amp;lr=&amp;id=csqLAgAAQBAJ&amp;oi=fnd&amp;pg=PP1&amp;dq=reigeluth&amp;ots=7I8aePlS1h&amp;sig=3pERHpIXV66BoY1VuGBfXT2e8d8#v=onepage&amp;q&amp;f=false\">Reigeluth, &amp; Carr-Chellman, 2009</a>). Specifically, cognitivism and constructivism theories are often cited for the metaverse. </span></p>\n<p id=\"ember1250\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> On the other hand, there is new research calling for more nuanced theories that reflect the social and learner-centered environments in the metaverse, e.g. connectivism or complexity theory (Checa &amp; Bustillo, 2023; <a href=\"http://dx.doi.org/10.1007/s11423-021-10005-8\">Schmidt &amp; Glaser, 2021</a>). Cognitivism and constructivism will be expanded upon here as they relate to research and application, beginning with cognitivism. </span></p>\n<p id=\"ember1251\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Cognitive learning theory historically reflects the strong influence from the computer science discipline wherein XR applications are understood as input/output platforms controlled by programming. Learner experiences are transactional and computational. A learner is faced with a choice, they take that choice, and the program reacts. As such, the experiences appear to have a cause-and-effect flow with computers and learners both mediating the processing. For instructional designers specifically, a deeper understanding of the cognitive theory of multimedia learning, where visuals and audio have been studied with respect to learning, is required to apply the advice within Section 4 of this series.</span></p>\n<p id=\"ember1252\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Theories begin with a set of assumptions based on observation. <a href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\">Mayer‚Äôs (2020</a>) cognitive theory of multimedia design has three critical assumptions:</span></p>\n<ul>\n<li><span style=\"font-family: helvetica;\"><strong>Dual channel:</strong> Humans can accept information only via sight and sound inputs.</span></li>\n<li><span style=\"font-family: helvetica;\"><strong>Limited capacity:</strong> Humans have neuronal limits as to how fast information can be sensed, kept in working memory, and then moved to long-term memory.</span></li>\n<li><span style=\"font-family: helvetica;\"><strong>Active processing:</strong> Humans bring prior experiences to their learning and actively think about information as they are processing it.</span></li>\n</ul>\n<p id=\"ember1253\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1254\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Based on those assumptions, the cognitive theory of multimedia design focuses on the human processing system.¬†</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/Mayer-Multimedia-Processing.jpg\" alt=\"Complex diagrams showing that multimedia input arrives into either the eyes or ears and can be converted and processed in working memory before moving to long term memory.\" width=\"662\" height=\"213\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-xs.jpg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-sm.jpg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-md.jpg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-lg.jpg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-xl.jpg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/Mayer-Multimedia-Processing-2xl.jpg 1920w\"><figcaption>Mayer's Cognitive Theory of Multimedia Design (2014 edition)</figcaption></figure>\n<p id=\"ember1254\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1256\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> There are two input channels (eyes and ears) where words and pictures enter sensory memory, then processing through working memory where sounds and images may interchange and conflict, finally moving to long term memory where information is integrated into prior knowledge. Words can be sensed by both eyes and ears. Selecting which words to focus on can cause conflict because the brain converts words to sounds inside of processing. This increases cognitive workload if an external voice is speaking while the learner‚Äôs internal voice is reading. This theory is relevant in that immersive experiences can provide words, voices, and graphics which, <i><strong>when simultaneously present</strong></i> in working memory, can increase cognitive workload, making long-term learning difficult. Because XR can provide an immersive environment of words, text, and sound surrounding learners, the risk is high that learners could be exposed to these cognitive conflicts. Section 4 will explore these pitfalls and how to avoid them. I will look briefly at constructivism next.¬†</span></p>\n<p id=\"ember1254\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1257\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Constructivist learning theory postulates that learners construct their knowledge through experience; learners do not arrive as blank slates. With a wide variety of possibilities of the metaverse, IDs can think that constructivism represents a constantly growing approach to learning - learners could even create objects in 3D to construct their knowledge. However, a closer examination of this theory is required. In constructivism, new knowledge is connected to older knowledge in a way similar to the act of construction, just as boards are attached one upon another to build up a building. For IDs, constructivist theory appears both while designing step-wise learning experiences and in knowing that learners arrive in XR <i>with preconceptions from prior experiences</i> (Checa &amp; Bustillo, 2023). It is in these preconceptions that learners will recognize and begin to process the experience. For example, if a learner arrives in an office building XR environment, they may begin to process the experience as work training. In this way, the learner might not need to be prompted that work behaviors are expected.¬†</span></p>\n<h2 id=\"ember1254\" class=\"ember-view reader-content-blocks__paragraph\" style=\"text-align: left;\"><span style=\"font-family: helvetica;\">Givens</span></h2>\n<p id=\"ember1259\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> It is important to note that both of these theories keep <strong>the learner,</strong> not the technology, <strong>primarily in mind</strong> when thinking of how learning will occur. Drawing from the indicated research, two further assumptions are held in this series and will be treated as givens:</span></p>\n<p>¬†</p>\n<p id=\"ember1254\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<ol>\n<li><span style=\"font-family: helvetica;\">Learners experience the virtual as real. (<a href=\"https://sts.stanford.edu/publications/experience-demand-what-virtual-reality-how-it-works-and-what-it-can-do\">Bailenson, 2018</a>, p. 46)</span></li>\n<li><span style=\"font-family: helvetica;\">Learning outcomes are expected to be equal to other media. (Mayer, 2020, p. 357)</span></li>\n</ol>\n<p id=\"ember1260\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1261\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Understanding how theory informs daily practice and design requires some finesse as rarely does an ID wake up and say, ‚ÄúI‚Äôm going to design pure cognitivist lessons today.‚Äù </span></p>\n<p>¬†</p>\n<blockquote id=\"ember1262\" class=\"ember-view\"><span style=\"font-family: helvetica;\"> Instead,<strong> theory provides the guide when the ID is facing a decision where the better path is not apparent. </strong></span></blockquote>\n<p id=\"ember1263\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Theories offer ‚Äúguidelines on motivations, learning processes and learning outcomes for the learners‚Äù (Checa &amp; Bustillo, 2023, p.5). A theory can point to methods, approaches, and strategies. Indeed, the mistake of not drawing upon a learning theory that is apparent in earlier research should not be repeated (<a href=\"https://www.researchgate.net/profile/Leonel-Morgado/publication/368434277_Educational_Practices_and_Strategies_with_Immersive_Learning_Environments_Mapping_of_Reviews_for_using_the_Metaverse/links/63ffc7680cf1030a5661703e/Educational-Practices-and-Strategies-with-Immersive-Learning-Environments-Mapping-of-Reviews-for-using-the-Metaverse.pdf\">Beck, Morgado, &amp; O‚ÄôShea</a>, 2023; Checa &amp; Bustillo, 2023; <a href=\"https://moodle2.units.it/pluginfile.php/562229/mod_resource/content/2/Brit%20J%20Educational%20Tech%20-%202014%20-%20Fowler%20-%20Virtual%20reality%20and%20learning%20%20Where%20is%20the%20pedagogy.pdf\">Fowler, 2015</a>).</span></p>\n<p>¬†</p>\n<p id=\"ember1264\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Overall, this series lands squarely within <a href=\"https://archive.org/details/pasteursquadrant00stok\">Pasteur's Quadrant</a>, contributing to both fundamental and practical applications (<a href=\"https://www.nature.com/articles/s41467-023-36741-4.pdf\">Shi &amp; Evans, 2023</a>).¬†</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/pasteursquadrant-911760832.jpg\" alt=\"Graphic display of Pasteur's Quadrant where basic fundamental research overlpas with everyday use research. This is similar to pasteurization; it pointed the way to germ theory (basic fundamental research) but applied in everyday life (by making milk safe to drink).\" width=\"798\" height=\"567\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-xs.jpg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-sm.jpg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-md.jpg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-lg.jpg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-xl.jpg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/pasteursquadrant-911760832-2xl.jpg 1920w\"><figcaption><span style=\"font-family: helvetica;\" data-keep-original-tag=\"false\" data-original-attrs=\"{&quot;style&quot;:&quot;&quot;}\">Pasteur's Quadrant: The type of research that quests for fundamental understanding AND can be used every day, like pasteurization. This article series lands in that sweet spot.</span></figcaption></figure>\n<p><span style=\"font-family: helvetica;\">Pasteur's Quadrant: The type of research that quests for fundamental understanding AND can be used every day, like pasteurization. This article series lands in that sweet spot.</span></p>\n<p id=\"ember1267\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">This series is fundamental because it draws primarily from the cognitive theory of multimedia design and it examines research designs and results. It is practical in that it provides many examples based on the author‚Äôs XR design experiences. (You'll see, it's coming in a future Part.) As Mayer suggested, this type of approach is ‚Äúbasic research in applied situations‚Äù (2020, p. 22). Pasteur‚Äôs Quadrant lends light on exploratory topics. In this case, I have some basic theory from 2D learning, but there is much more 3D nuance unknown. Progress in this field will require that theory and applied research move forward hand in hand. </span></p>\n<p id=\"ember1264\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1268\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> Fortunately, being in Pasteur‚Äôs quadrant provides hints at further unanswered puzzles beyond this series. For example, what is the connection between the popular XR game emotional coinage of fear and successful XR applications for the training of the emergency services: fire, police, military, and medical personnel? The answer to that quest will wait for another day. Before I begin an examination of research myths (upcoming Part 3), I need to explain what can and cannot be covered in a series of this breadth.</span></p>\n<h2 class=\"ember-view\"><span style=\"font-family: helvetica;\">Scope</span></h2>\n<p id=\"ember1270\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> This series leaves many topics by the wayside: defining the metaverse in education, qualifying and categorizing experiences, affordances and constraints, and accessibility options. Doubtless, each of those topics deserves a series of its own [note to self] but there is no space to address them here. This series does provide insight into four areas:</span></p>\n<ul>\n<li><span style=\"font-family: helvetica;\">interpreting research to rout out myths</span></li>\n<li><span style=\"font-family: helvetica;\">looking for the characteristics of success in XR educational designs</span></li>\n<li><span style=\"font-family: helvetica;\">using ID theory to inform the building blocks of design</span></li>\n<li><span style=\"font-family: helvetica;\">tips for implementing an XR design project.</span></li>\n</ul>\n<p id=\"ember1271\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p id=\"ember1272\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> The specific research gap that this series addresses is the missing connection between known design principles and practical applications of ID in the metaverse. <a href=\"https://www.researchgate.net/publication/370221242_The_Immersion_Principle_in_Multimedia_Learning\">Makransky</a> commented on the lack of connection between the cognitive theory of multimedia design and instructional design in virtual reality,¬† stating that ‚Äúresearch that has investigated instructional design implications in immersive learning environments is severely limited‚Äù (2023, p. 5). Beck, Morgado, and O‚ÄôShea surveyed that ‚Äúmostly papers discuss opportunities and challenges or compare outcomes, rather than expose details on educational practices or strategies‚Äù (2023, p. 2).¬† Reigeluth and Honebein suggested that research-to-prove should be replaced with research-to-improve when a technology is in its early developmental stage (2023). Such research should limit itself to suggesting ‚Äúpossible ideas for actions and improvement‚Äù (<a href=\"https://www.researchgate.net/profile/Charles-Reigeluth/publication/371304955_How_Do_We_Solve_a_Problem_Like_Media_and_Methods_207/links/647e04b6b3dfd73b7767f1d2/How-Do-We-Solve-a-Problem-Like-Media-and-Methods-207.pdf\">Reigeluth &amp; Honebein, 2023</a>, p. 2). Finally, the emergent use of XR technology has precipitated haphazard designs lacking guidance:</span></p>\n<p id=\"ember1273\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> \"In these early days, trial and error plays an outsized role in design. Education researchers borrow heavily from the entertainment designers, who focus on engagement, and not necessarily on retention of content. The dearth of studies highlights the urgency for a set of guidelines for designing content that allows users to make appropriate choices in a spherical space.\" (Johnson-Glenberg, 2018, p. 7).</span></p>\n<p id=\"ember1274\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> It is hoped that this series lends to two facets of instructional design. First, the <strong>thinking</strong> side of design, when a designer must choose one approach or another. This series strives to give the best advice. Second, the <strong>implementing</strong> side of design where designers arrive directly into the metaverse to see what their learners will experience. This series, then, points the way.¬†</span></p>\n<p id=\"ember1274\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">Part 3 will approach research myths surrounding the metaverse in education.¬†¬†</span></p>\n<hr>\n<p id=\"ember1274\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">Part 1</span><br><br></p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEh9wqDTa84lZOgZFYSqNxulKkzfrtsgh15mOgbRXx6lC5lHgfyPXwYunfFxnhJdUSCtbArl_JhjAoT4X9nY8hMJoiDa2UG1AI_Ma36F_U9VU1RGLpeOZThi7qvFv-umDb0XF7OnJsFUpSiZL1p_Gj0qqmkkXwjkqd4cPXl3cJ4xgl8OYWCgQDiCcy2WHFg/s1456/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b.png\" alt=\"Decorative image of scholars studying in a retrofuturistic blue room.\" width=\"640\" height=\"358\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/responsive/heather_dodds_in_the_style_of_science_fiction_retrofuturism_mys_2770c22f-5166-489a-bfb5-86e8347f580b-2xl.png 1920w\"></a></div>\n<p style=\"text-align: center;\">¬†Theory, theory everywhere.<br><br></p>\n<p>#InstructionalDesign #Metaverse #XR #MR #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #Cognitive #Theory #Design #Principles #Virtual #VR #Reality #Connectivism #Complexity #ComputerScience #DualChannel #LimitedCapacity #ActiveProcessing #Constructivism #PasteursQuadrant #Thinking #Designing<br><br>This was originally posted on October 1, 2023 and is reposted with slight editing.</p>\n<p id=\"ember1247\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<p><span id=\"docs-internal-guid-1a157d8c-7fff-fd6c-3865-c5ad831572ad\" style=\"background-color: transparent; color: black; font-family: Times,serif; font-size: 10pt; font-style: normal; font-variant: normal; font-weight: 400; text-decoration: none; vertical-align: baseline;\">¬†</span></p>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/702/ID-in-the-Metaverse-Blog-Banner-23.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-01T14:15:00-04:00",
            "date_modified": "2025-07-31T17:15:21-04:00"
        },
        {
            "id": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-1-introduction.html",
            "url": "https://hobbs-hobbler.github.io/hobbs.blog/instructional-design-in-the-metaverse-part-1-introduction.html",
            "title": "Instructional Design in the Metaverse Part 1 Introduction",
            "summary": "The promise of the metaverse in education is like a mirage in the desert. Educators seem to be forever anticipating the arrival of the metaverse but still not yet embracing it. However, this waiting time has not been without value as solid research foundations have&hellip;",
            "content_html": "<p id=\"ember2116\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">The promise of the metaverse in education is like a mirage in the desert. Educators seem to be forever anticipating the arrival of the metaverse but still not yet embracing it. </span></p>\n<p id=\"ember2117\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> However, this waiting time has not been without value as solid research foundations have been built. In an article titled ‚Äú<a href=\"https://www.insidehighered.com/digital-learning/blogs/education-time-corona/hottest-job-higher-education-instructional-designer\">The Hottest Job in Higher Education: Instructional Designer</a>‚Äù, Decherney and Levander asserted that as instructional designers (IDs) have become the ‚Äúsherpas of online learning teams, experts in <i>how</i> to teach and design a course‚Äù (2020, para. 5).</span></p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/hottest-job.png\" alt=\"Screen capture of headline with text: The Hottest Job in Higher Education: Instructional Designer\" width=\"1121\" height=\"390\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/hottest-job-2xl.png 1920w\"></figure>\n<p id=\"ember2119\" class=\"ember-view reader-content-blocks__paragraph\">It follows that instructional designers will be the experts by reading research and determining the best route to the metaverse promise.</p>\n<figure class=\"post__image\"><img loading=\"lazy\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/this-is-the-way-2.jpeg\" alt=\"Graphic image with text: This is the way. Helmet and walking Mandalorian.\" width=\"1140\" height=\"989\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-xs.jpeg 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-sm.jpeg 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-md.jpeg 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-lg.jpeg 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-xl.jpeg 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/this-is-the-way-2-2xl.jpeg 1920w\"></figure>\n<p id=\"ember2121\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">This article series intends to provide guidance for instructional designers entering this new and rapidly changing space by straddling between what is known and unknown in instructional design in the metaverse. Early research that addresses the metaverse ‚Äútends to focus on outcomes-based research while neglecting the important details of how something was accomplished‚Äù (<a href=\"https://www.researchgate.net/profile/Leonel-Morgado/publication/368434277_Educational_Practices_and_Strategies_with_Immersive_Learning_Environments_Mapping_of_Reviews_for_using_the_Metaverse/links/63ffc7680cf1030a5661703e/Educational-Practices-and-Strategies-with-Immersive-Learning-Environments-Mapping-of-Reviews-for-using-the-Metaverse.pdf\">Beck, Morgado, &amp; O‚ÄôShea, 2023</a>, p. 1). Studies can also target emergent cause-and-effect or comparison relationships and <strong>ignore</strong> known educational practices and principles. Quests can contain grand promises, spurring a rush to implement, followed by unmet hopes and expectations (<a href=\"https://www.cambridge.org/highereducation/books/multimedia-learning/FB7E79A165D24D47CEACEB4D2C426ECD#overview\">Mayer, 2020</a>, p. 13). If administrators determine that the metaverse does contain unmet hopes, future funding for uses that truly could change education for the better will dry up.</span></p>\n<p id=\"ember2122\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> After this first Introduction section, the second of eight sections will examine <strong>research myths</strong> in the educational metaverse. These myths include that the metaverse will cause more learning at a faster rate and reach learners in new ways. I will look closely at what the research currently says for and against seven specific claims. In the third section, I will look at what the research is pointing to as <strong>characteristics of success</strong> when considering the incorporation and implementation of the metaverse. The characteristics do not seem to arrive in popular metaverse claims, but like the slow and steady tortoise, they seem to predict the winners of the race. In Sections 4 and 5, I will cover the detailed work of instructional design, targeting especially <strong>what we already know about multimedia learning</strong> and what will be uncovered in the metaverse. Section 6 will discuss <strong>the current limitations</strong> of using research to drive instructional design in the metaverse. Finally, Sections 7 and 8 are written to leave the reader with<strong> hope and soaring possibilities</strong> in mind. Because instructional design in the metaverse is an emergent topic, some discoveries are yet to arrive to their eureka moments; those will fall completely outside of our prediction. Thus, this series will have 8 sections but innumerable (until it is done) parts. </span></p>\n<div class=\"ivm-image-view-model\">\n<div class=\"ivm-view-attr__img-wrapper display-flex\"><figure class=\"ivm-view-attr__img--centered reader-image-block__img evi-image lazy-image ember-view\"><img loading=\"lazy\" id=\"ember2123\"  src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/1695832800198\" alt=\"\"></figure>¬†</div>\n<div class=\"ivm-view-attr__img-wrapper display-flex\">\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjKEuiXpo8D5cOyyFj-XdvHW4iorTm1kgKoYOQyoB6FNXQZQ0faNQRboIxJEmDavDnV0nJnwCy4KjT_kHHSDT9aFmvgfV2tkE7Kh5qpOP1Gk8h1hliVNX2rqR_vSJGQUVqoAzYk2WoMWAqS0TU4OV3omfM1jAZOaJuHLXqPTUQNnr7CVJpK_kbzBL-e-vQ/s1456/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12.png\" alt=\"Decorative image of man standing and looking at digital nether in a desert.\" width=\"640\" height=\"358\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_a_mirage_in_a_desert_scene_the_mirage__8866e6a5-4ceb-4421-85f1-ea5fd11e2c12-2xl.png 1920w\"></a></div>\n</div>\n<div class=\"ivm-view-attr__img-wrapper display-flex\" style=\"text-align: center;\"><span style=\"font-family: helvetica;\">¬†This conceptual series will propose instructional design principles for the metaverse</span>.</div>\n<div class=\"ivm-view-attr__img-wrapper display-flex\">\n<h2 style=\"text-align: left;\">Approach</h2>\n</div>\n<div class=\"ivm-view-attr__img-wrapper display-flex\">\n<p id=\"ember2125\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">This article series explores the topic with an evidence-based learner-centric approach. That approach fits best for instructional design, a discipline that considers the learning needs of the learner first and foremost. This chapter does not support the use of the metaverse in education for the sake of the cross or extended reality (XR) technology itself, which could be considered a technology-centered approach (Mayer, 2020).</span></p>\n<p id=\"ember2125\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n<blockquote>Instead, metaverse solutions should be selected when they are best fit for the instructional situation at hand. In many cases, they will be. But in some cases, <strong>they will not</strong>.</blockquote>\n<p id=\"ember2127\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> This series strives to illuminate the characteristics and conditions to consider while keeping the learner and not the technology in the center of focus.</span></p>\n<p id=\"ember2128\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\"> While maintaining that learner focus, this series will use several vocabulary terms and acronyms. Terms such as metaverse, cross reality, or¬† extended reality (XR) will be used interchangeably to refer to the entire technological incorporation. However, this author will use XR to refer more often to the technologies, i.e. hardware and software (<a href=\"https://doi.org/10.1007/978-3-030-58948-6_4\">Ziker, Truman, &amp; Dodds, 2021</a>), and metaverse to refer to a computer-mediated experience whether it is a game, application, or platform. Two-dimensional (2D) experiences, including monitors and simulations, will often be juxtaposed with three-dimensional (3D) experiences, including headsets or the immersive web (WebXR). The terms instructional design (ID) and instructional designers (IDs) are only separated by the discipline of how people learn and how to design instruction to help that process <i>versus </i>being the one who practices it. Nevertheless, popular terms like learning experience design (LXD) and learning experience designers (LXDs) convey equivalent meaning to aims and mission of instructional design. This chapter will refer to any planned 3D educational interactions as experiences. Indeed, the wide variety of vocabulary and terms is ‚Äúa characteristic of the early evolution of a branch of technology‚Äù (<a href=\"https://edtechbooks.org/id_highered/immersive_learning_e\">Dodds, 2021</a>, para. 5). </span></p>\n<p id=\"ember2129\" class=\"ember-view reader-content-blocks__paragraph\"><span style=\"font-family: helvetica;\">Part 2 will cover my theoretical basis and scope.¬†</span></p>\n<p>¬†</p>\n<div class=\"separator\" style=\"clear: both; text-align: center;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgbMIQSJVhL8qChDDmUDPBOFMB8dWRMkr7je6zX0_9688ERvQ8XywPejR9GsntMdxBGsw9zzb8fN0vmLngKybgis-YMbYbjxhzhhsDdmS4UUnm9OGW2VdxjSLkLJQIDPLUguh-WAM687f1Mb3Bqc2G3DFR1d2D6Nvv9QlPx7J61d00kTKNENheCE5DmP9E/s1456/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b.png\" style=\"margin-left: 1em; margin-right: 1em;\"><img loading=\"lazy\" src=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b.png\" alt=\"Decorative image of science fiction moonbase.\" width=\"640\" height=\"358\" border=\"0\" sizes=\"(max-width: 1920px) 100vw, 1920px\" srcset=\"https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-xs.png 640w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-sm.png 768w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-md.png 1024w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-lg.png 1366w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-xl.png 1600w ,https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/responsive/heather_dodds_film_still_wide_shot_moon_base_glowing_moon_bases_bb3cff5a-3298-40ed-998c-37b2e71b9f2b-2xl.png 1920w\"></a></div>\n<div>¬†</div>\n<div><hr></div>\n<p><span style=\"font-family: helvetica;\">¬†#InstructionalDesign #XR #Multimedia #Principles #Mayer #LXD #ID #InstructionalDesigner #WebXR #3D #2D #Approach #LearnerCentric #ResearchMyths #WhatWeKnow #WhatWeDoNotKnow #OnlineSherpas #ThisIsTheWay<br><br>This article was originally published on October 1, 2023 and simultaneously published on LinkedIn articles here: https://www.linkedin.com/pulse/instructional-design-metaverse-part-1-heather-dodds-ph-d-/</span></p>\n<p id=\"ember2129\" class=\"ember-view reader-content-blocks__paragraph\"></p>\n</div>\n<div class=\"ivm-view-attr__img-wrapper display-flex\">¬†</div>\n</div>",
            "image": "https://hobbs-hobbler.github.io/hobbs.blog/media/posts/703/ID-in-the-Metaverse-Blog-Banner-21-2.png",
            "author": {
                "name": "Heather Dodds"
            },
            "tags": [
                   "Metaverse"
            ],
            "date_published": "2023-10-01T13:59:00-04:00",
            "date_modified": "2025-07-31T17:06:02-04:00"
        }
    ]
}
